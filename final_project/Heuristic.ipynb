{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Heuristic.ipynb`: Calculate a heruistic for the travel time\n",
    "We calculate the heuristic the follwing way:<br>\n",
    "The heuristic from station a to station b is the minimum time one has to be sitting in a train to get from a to b. In other words, we assume that one can take trains like cars, no timetable limits are imposed. This will clearly give an overly optimistic estimate, as the waiting times from the timetables are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://iccluster042.iccluster.epfl.ch:4048\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.0.0-78</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sbb-rychener</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd622b77c88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import unix_timestamp, round\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName('sbb-{0}'.format(getpass.getuser())) \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.port.maxRetries', '100') \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Filter\n",
    "First, we filter on only the stations in a 10km radius around Zürich. This allows for computation in \"reasonable\" time on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_squared(n1,e1, n2, e2):\n",
    "    '''Calculates the euclidean distance between two points'''\n",
    "    eucl_dist2 = ((n1-n2)*(n1-n2)+ (e1-e2)*(e1-e2))\n",
    "    return eucl_dist2\n",
    "\n",
    "coords_zurich = (683144.0, 248040.0) # X, Y  (E,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of train station localisation\n",
    "df_stops = spark.read.csv('stops.txt', sep=';', header=True).select('Dst-Bezeichnung-offiziell','KOORDE','KOORDN')\\\n",
    ".withColumnRenamed('Dst-Bezeichnung-offiziell','station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.withColumn('dist2', distance_squared(coords_zurich[1], coords_zurich[0], df_stops.KOORDN, df_stops.KOORDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.filter(df_stops.dist2<=10000**2).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_filter = df_stops.select('station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_data = spark.read.csv('/datasets/sbb/2017/10/2017-10-17istdaten.csv.bz2', header=True, sep=\";\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "istdaten = swiss_data.join(stops_filter, swiss_data.HALTESTELLEN_NAME == stops_filter.station_name, 'inner').persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = istdaten.select('FAHRT_BEZEICHNER', 'HALTESTELLEN_NAME', 'ANKUNFTSZEIT', 'ABFAHRTSZEIT').persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.ANKUNFTSZEIT.isNotNull() & df.ABFAHRTSZEIT.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------------+----------------+\n",
      "|FAHRT_BEZEICHNER|HALTESTELLEN_NAME|    ANKUNFTSZEIT|    ABFAHRTSZEIT|\n",
      "+----------------+-----------------+----------------+----------------+\n",
      "|  85:11:1255:001|        Zürich HB|17.10.2017 08:26|17.10.2017 08:37|\n",
      "|  85:11:1258:001|        Zürich HB|17.10.2017 21:23|17.10.2017 21:34|\n",
      "|  85:11:1507:002|        Zürich HB|17.10.2017 06:30|17.10.2017 06:39|\n",
      "|  85:11:1507:002| Zürich Flughafen|17.10.2017 06:49|17.10.2017 06:51|\n",
      "|  85:11:1509:002|        Zürich HB|17.10.2017 07:30|17.10.2017 07:39|\n",
      "|  85:11:1509:002| Zürich Flughafen|17.10.2017 07:49|17.10.2017 07:51|\n",
      "|  85:11:1510:002| Zürich Flughafen|17.10.2017 07:11|17.10.2017 07:13|\n",
      "|  85:11:1510:002|        Zürich HB|17.10.2017 07:23|17.10.2017 07:30|\n",
      "|  85:11:1511:002|        Zürich HB|17.10.2017 08:30|17.10.2017 08:39|\n",
      "|  85:11:1511:002| Zürich Flughafen|17.10.2017 08:49|17.10.2017 08:51|\n",
      "|  85:11:1512:002| Zürich Flughafen|17.10.2017 08:11|17.10.2017 08:13|\n",
      "|  85:11:1512:002|        Zürich HB|17.10.2017 08:23|17.10.2017 08:30|\n",
      "|  85:11:1513:003|        Zürich HB|17.10.2017 09:30|17.10.2017 09:39|\n",
      "|  85:11:1513:003| Zürich Flughafen|17.10.2017 09:49|17.10.2017 09:51|\n",
      "|  85:11:1514:002| Zürich Flughafen|17.10.2017 09:11|17.10.2017 09:13|\n",
      "|  85:11:1514:002|        Zürich HB|17.10.2017 09:23|17.10.2017 09:30|\n",
      "|  85:11:1515:003|        Zürich HB|17.10.2017 10:30|17.10.2017 10:39|\n",
      "|  85:11:1515:003| Zürich Flughafen|17.10.2017 10:49|17.10.2017 10:51|\n",
      "|  85:11:1516:002| Zürich Flughafen|17.10.2017 10:11|17.10.2017 10:13|\n",
      "|  85:11:1516:002|        Zürich HB|17.10.2017 10:23|17.10.2017 10:30|\n",
      "+----------------+-----------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Join to get trips\n",
    "We perform a join with itself, to get the trips. The time for each trip is negative if the trip goes in the opposite direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = ['FAHRT_BEZEICHNER', 'HALTESTELLEN_NAME', 'ANKUNFTSZEIT', 'ABFAHRTSZEIT']\n",
    "df1 = df\n",
    "df2 = df\n",
    "for c in columns:\n",
    "    df1 = df1.withColumnRenamed(c, c+'_1')\n",
    "    df2 = df2.withColumnRenamed(c, c+'_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+----------------+----------------+\n",
      "|FAHRT_BEZEICHNER_1|HALTESTELLEN_NAME_1|  ANKUNFTSZEIT_1|  ABFAHRTSZEIT_1|\n",
      "+------------------+-------------------+----------------+----------------+\n",
      "|    85:11:1255:001|          Zürich HB|17.10.2017 08:26|17.10.2017 08:37|\n",
      "|    85:11:1258:001|          Zürich HB|17.10.2017 21:23|17.10.2017 21:34|\n",
      "+------------------+-------------------+----------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------------+-------------------+----------------+----------------+\n",
      "|FAHRT_BEZEICHNER_2|HALTESTELLEN_NAME_2|  ANKUNFTSZEIT_2|  ABFAHRTSZEIT_2|\n",
      "+------------------+-------------------+----------------+----------------+\n",
      "|    85:11:1255:001|          Zürich HB|17.10.2017 08:26|17.10.2017 08:37|\n",
      "|    85:11:1258:001|          Zürich HB|17.10.2017 21:23|17.10.2017 21:34|\n",
      "+------------------+-------------------+----------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(2)\n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df1.join(df2, df1.FAHRT_BEZEICHNER_1==df2.FAHRT_BEZEICHNER_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = full_df.withColumn('time', (unix_timestamp(\"ANKUNFTSZEIT_1\", 'dd.MM.yyyy HH:mm') - \\\n",
    "                               unix_timestamp(\"ABFAHRTSZEIT_2\",'dd.MM.yyyy HH:mm'))/60)\\\n",
    "                                .select('HALTESTELLEN_NAME_1', 'HALTESTELLEN_NAME_2', 'time')\n",
    "times_df = times_df.filter(times_df.time>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----+\n",
      "|HALTESTELLEN_NAME_1|HALTESTELLEN_NAME_2|time|\n",
      "+-------------------+-------------------+----+\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "|          Zürich HB|   Zürich Flughafen|10.0|\n",
      "|   Zürich Flughafen|          Zürich HB|10.0|\n",
      "+-------------------+-------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "times_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating all the travel times, we now build our precomputed dictionnary and Distance Matrix. We initialise the Distance matrix with 12h, and add the connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [r[0] for r in times_df.select('HALTESTELLEN_NAME_1').distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stations = len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_travel_times = np.full((n_stations,n_stations), 60*24.) #maximal travel time is 1 day (this is way to much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1440., 1440., 1440., ..., 1440., 1440., 1440.],\n",
       "       [1440., 1440., 1440., ..., 1440., 1440., 1440.],\n",
       "       [1440., 1440., 1440., ..., 1440., 1440., 1440.],\n",
       "       ...,\n",
       "       [1440., 1440., 1440., ..., 1440., 1440., 1440.],\n",
       "       [1440., 1440., 1440., ..., 1440., 1440., 1440.],\n",
       "       [1440., 1440., 1440., ..., 1440., 1440., 1440.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_travel_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = times_df.filter(times_df.HALTESTELLEN_NAME_1!=times_df.HALTESTELLEN_NAME_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_times = trips_df.groupBy('HALTESTELLEN_NAME_1', 'HALTESTELLEN_NAME_2')\\\n",
    "                        .agg(F.min(trips_df.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = dist_times.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_dict = dict(zip(stations, range(n_stations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Floyd-Warshall Algorithm to find shortest path distances\n",
    "Now, we use the Floyd-Warshall Algorithm to calculate our distance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, add the train connections to our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add edges\n",
    "for i, r in df_pd.iterrows():\n",
    "    _i = stations_dict[r['HALTESTELLEN_NAME_1']]\n",
    "    _j = stations_dict[r['HALTESTELLEN_NAME_2']]\n",
    "    _t_min = r['min(time)']\n",
    "    min_travel_times[_j,_i] = _t_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, self-distance is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-distance is 0\n",
    "for i in range(n_stations):\n",
    "    min_travel_times[i,i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, add walking times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load all the necessary data\n",
    "import pickle\n",
    "with open('./data/station_from_index.pkl', 'rb') as handle:\n",
    "    station_from_index = pickle.load(handle)\n",
    "with open('./data/index_from_station.pkl', 'rb') as handle:\n",
    "    index_from_station = pickle.load(handle)\n",
    "walking_distances = np.load('./data/walking_distances.npy')\n",
    "walking_distances = np.sqrt(walking_distances)\n",
    "\n",
    "# definition of the maximum walking time\n",
    "MAX_WALKING_TIME = 5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s1 in list(stations_dict.keys()):\n",
    "    if s1 in index_from_station.keys():\n",
    "        # get the distances for all stations\n",
    "        walking_times = walking_distances[index_from_station[s1],:]\n",
    "        # get stations in walking distance\n",
    "        close_stations = np.argwhere(walking_times<MAX_WALKING_TIME)\n",
    "\n",
    "        # get the names of the stations\n",
    "        station_names = [station_from_index[i] for i in close_stations.flatten().tolist()  \\\n",
    "                         if i!=index_from_station[s1]]\n",
    "        # get the estimated arrival times for all stations\n",
    "        arrival_times = (walking_times[close_stations].flatten()).tolist()\n",
    "        for i in range(len(station_names)):\n",
    "            s2 = station_names[i]\n",
    "            if s2 not in stations_dict.keys():\n",
    "                continue\n",
    "            _i = stations_dict[s2]\n",
    "            _j = stations_dict[s1]\n",
    "            _t_min = arrival_times[i]/60\n",
    "            if _t_min<min_travel_times[_j,_i]:\n",
    "                min_travel_times[_j,_i] = _t_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find distances on this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main path finding algorithm\n",
    "for k in range(n_stations):\n",
    "    for i in range(n_stations):\n",
    "        for j in range(n_stations):\n",
    "            if min_travel_times[i,j] > min_travel_times[i,k] + min_travel_times[k,j]:\n",
    "                min_travel_times[i,j] = min_travel_times[i,k] + min_travel_times[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  9.        ,  9.        , ..., 10.        ,\n",
       "         9.4472774 , 11.        ],\n",
       "       [ 9.        ,  0.        ,  2.        , ..., 14.        ,\n",
       "        11.68960536, 15.        ],\n",
       "       [ 8.        ,  2.        ,  0.        , ..., 13.        ,\n",
       "         9.68960536, 14.        ],\n",
       "       ...,\n",
       "       [12.        , 16.        , 16.        , ...,  0.        ,\n",
       "        17.        ,  7.        ],\n",
       "       [10.36895614, 13.        , 12.        , ..., 15.36895614,\n",
       "         0.        , 16.36895614],\n",
       "       [14.        , 18.        , 18.        , ...,  8.        ,\n",
       "        19.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_travel_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/min_travel_times', min_travel_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/stations_dict', 'wb') as handle:\n",
    "    pickle.dump(stations_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function to use in the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we give the function to be used in the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/stations_dict', 'rb') as handle:\n",
    "    stations_dict = pickle.load(handle)\n",
    "min_travel_times = np.load('./data/min_travel_times.npy')\n",
    "\n",
    "def get_heuristic(city_a,city_b):\n",
    "    '''\n",
    "    Calculates the heuristic of time in minutes between two city taking a train\n",
    "    '''\n",
    "    # try to find connection in our adjacency matrix calculated in Heuristic.ipynb\n",
    "    if city_a in stations_dict and city_b in stations_dict:\n",
    "        i = stations_dict[city_a]\n",
    "        j = stations_dict[city_b]\n",
    "        estimated_time = min_travel_times[i,j]\n",
    "        if estimated_time!=1440:\n",
    "            # estimated_time=1440: no possible connection was found when building the Heuristic adjacency matrix\n",
    "            return estimated_time\n",
    "    \n",
    "    avg_speed = 1600\n",
    "    try :\n",
    "        df_a = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_a).collect()\n",
    "        x_a = float(df_a[0]['KOORDE'])\n",
    "        y_a = float(df_a[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_a,'is invalide')\n",
    "        return 0\n",
    "    try :\n",
    "        df_b = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_b).collect()\n",
    "        x_b = float(df_b[0]['KOORDE'])\n",
    "        y_b = float(df_b[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_b,'is invalide')\n",
    "        return 0\n",
    "    eucl_dist = math.sqrt((x_a-x_b)*(x_a-x_b)+ (y_a-y_b)*(y_a-y_b))\n",
    "    return eucl_dist/avg_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_heuristic('Zürich HB','Zürich, Bahnhofquai/HB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
