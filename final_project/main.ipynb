{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://iccluster042.iccluster.epfl.ch:4047\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.0.0-78</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sbb2-opeter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f179fbcee80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from queue import *\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import time\n",
    "#from geopy.distance import distance as geo_dist\n",
    "import scipy.stats\n",
    "from bisect import bisect_right\n",
    "import getpass\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from heapq import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName('sbb2-{0}'.format(getpass.getuser())) \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.port.maxRetries', '100') \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm \n",
    "\n",
    "The search algorithm we decided to use is a modified version of the A* algorithm. If eta is the estimated arrival time of a path, then eta(n) = g(n) + E[d(n)] + h(n) with g(n) the predicted arrival time of the last connection, E[d(n)] the expected delay of the last trip and h(n) the heuristic estimating the time remanning to get from the nth stop to the arrival station. \n",
    "\n",
    "The priority queue is performed on eta. As the eta is always an overly optimistic estimation of the arrival time, no trip can ever perform better that the current lowest eta. Meaning that when the station with the lowest eta is the destination station we are assured that any further computed trip would take more time, and have therefore find the time optimal trip. \n",
    "\n",
    "At each step, the stop with the lowest eta is extracted from the priority queue and all states that can be reached from this point are computed. The states that are better that what we already found and have a higher probability to succeed that the threshold set by the user are added to the priority queue. The program stops when the destination station is the station extracted from the priority queue. \n",
    "\n",
    "**Defining a state**\n",
    "A state is defined by a station, an eta, the probability to be at the state and the arrival time of the trip that took us to that state. The eta is a very optimistic estimation of the arrival time. The actual arrival time will always we either equal or higher that the estimated arrival time. \n",
    "\n",
    "**Creating a state**\n",
    "When the nth state is \"poped\" from the priority list, a list of neighbouring stations and trip to get to them from the nth state station is computed. \n",
    "For each element of this list a new state is created :\n",
    "    - The new eta = (predicted arrival time to station n+1) + (expected delay from the trip from n to n+1) +  (heuristic at n+1) \n",
    "    - The probability of being at the state = Pboarding * P being at the nth state \n",
    "    - The P of boarding = probability that delay if the train taken to nth station arrives in time to take the train to the n+2 station. \n",
    "If the trip to the next station is by walking we set the eta as the current time + walking time + heuristic of the n+1 state and the P of boarding is set to 1\n",
    "\n",
    "**Heursitic** \n",
    "\n",
    "For the Heuristic, we create a graph that contains as edge weights between nodes (stations) the fastest direct transport between them (walking if in range, train if there is a train-line connecting the 2 stations, no edge otherwise). We then precalculated the distance-matrix for this graph.\n",
    "\n",
    "**Probability of delay of a train**\n",
    "\n",
    "The probability distribution of the delays of each trains is approximated by assuming that each sort of train (linien_text) have the same probability distribution function (pdf) at each stations. The pdf is estimated to be lognorm. Details of estimation of train delays are in the Delay Analysis notebook. To estimate the arrival time of a train we use the predicted arrival time + the expected delay.\n",
    "\n",
    "**Probability of boarding**\n",
    "\n",
    "If a user takes *train 1* to station a and *train 2* to station b.\n",
    "\n",
    "We want the probability to board *train 2* at station a, meaning the probability for *train 1* to arrive at station a before *train 2* leave the station. \n",
    "\n",
    "Here only arrival time of trains are random variable, whereas departure are set as deterministic values, to avoid to offer a plan counting on the late departure of a train. We also estimated that changing train takes around 3 minutes. This could be fine tuned by for exemple testing if the arrival platform is the same as the next departure platform. \n",
    "\n",
    "The probability of boarding *train 2* is therefore calculated as the probability that the *train 1* is delayed of less than the time between the predicted arrival of *train 1* and the departure of *train 2*.   \n",
    "\n",
    "**Eliminating bad path**\n",
    "\n",
    "To reduce the number of visited path we keep track of the stations we already visited. A station that already as been visited by the algorithm can be considered again either if the subsequent estimated time  of arrival is better that the previous one or if the probability to successfully be at this stop is higher that the previous one. If either or both of the condition are met, the trip is added the priority queue. Otherwise we can ignore it. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Filter\n",
    "To get information about the localization of the bus/train stop we used the SBB Didok documentation in which name are compatible with the name in the trip data.\n",
    "\n",
    "\n",
    "First, we filter on only the stations in a 10km radius around ZÃ¼rich. This allows for computation in \"reasonable\" time on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_squared(n1,e1, n2, e2):\n",
    "    '''Calculates the euclidean distance between two points'''\n",
    "    eucl_dist2 = ((n1-n2)*(n1-n2)+ (e1-e2)*(e1-e2))\n",
    "    return eucl_dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_zurich = (683144.0, 248040.0) # X, Y  (E,N), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of train station localisation\n",
    "df_stops = spark.read.csv('stops.txt', sep=';', header=True).select('Dst-Bezeichnung-offiziell','KOORDE','KOORDN')\\\n",
    ".withColumnRenamed('Dst-Bezeichnung-offiziell','station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.withColumn('dist2', distance_squared(coords_zurich[1], coords_zurich[0], df_stops.KOORDN, df_stops.KOORDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.filter(df_stops.dist2<=10000**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering the Didok**\n",
    "\n",
    "The Dikdoc documentation includes bridges and other info. As we are only interested in the stops we filter by keeping only the name that appear in the general trip data of a specific day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_data = spark.read.csv('/datasets/sbb/2017/10/2017-10-17istdaten.csv.bz2', header=True, sep=\";\")\n",
    "cross_table = df_stops.join(swiss_data, swiss_data.HALTESTELLEN_NAME == df_stops.station_name, 'inner').persist()\n",
    "df_stops = cross_table.select('station_name','KOORDE','KOORDN').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = cross_table.select('station_name','KOORDE','KOORDN').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_filter = df_stops.select('station_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Delay\n",
    "\n",
    "We get the train delay distribution as explained in the delay analysis. We chose to keep the dataframe in memory all the time. This is possible here since it is not too long, but a more scalable methods would be to load the dataframe each time by chunks as explained in the delay analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "delays_df = pd.read_csv(DATA_PATH+'params_by_stop_line.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "We now want to read data from the sbb files and extract usefull information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find station accessible by walking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds stations in proximity of station of interest. We used 5 minute as an upperbound on the time of walking. Distance is computed as simply the euclidian distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidiandist(x_a,x_b,y_a,y_b):\n",
    "    # We assumed that average speed of the user is of 5km/h\n",
    "    avg_speed = 1.388889\n",
    "    eucl_dist = math.sqrt((x_a-x_b)*(x_a-x_b)+ (y_a-y_b)*(y_a-y_b))\n",
    "    return eucl_dist/avg_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load all the necessary data\n",
    "import pickle\n",
    "with open('./data/station_from_index.pkl', 'rb') as handle:\n",
    "    station_from_index = pickle.load(handle)\n",
    "with open('./data/index_from_station.pkl', 'rb') as handle:\n",
    "    index_from_station = pickle.load(handle)\n",
    "walking_distances = np.load('./data/walking_distances.npy')\n",
    "walking_distances = np.sqrt(walking_distances)\n",
    "\n",
    "# definition of the maximum walking time\n",
    "MAX_WALKING_TIME = 10*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walking_stations(current_station, current_time, way, isadvance):\n",
    "    if way == 'forward':\n",
    "        # get the distances for all stations\n",
    "        walking_times = walking_distances[index_from_station[current_station],:]\n",
    "        # get stations in walking distance\n",
    "        close_stations = np.argwhere(walking_times<MAX_WALKING_TIME)\n",
    "        # remove station itself\n",
    "        close_stations = [i for i in close_stations.flatten().tolist()  \\\n",
    "                         if i!=index_from_station[current_station]]\n",
    "        # get the names of the stations\n",
    "        station_names = [station_from_index[i] for i in close_stations]\n",
    "        # get the estimated arrival times for all stations\n",
    "        arrival_times = (walking_times[close_stations].flatten() + current_time).tolist()\n",
    "        # get the other information necessary\n",
    "        line_type = [None]*len(station_names)\n",
    "        departure_time = [current_time]*len(station_names)\n",
    "\n",
    "\n",
    "        # return the tuples we want\n",
    "        walking_stops_tuples = list(zip(line_type, departure_time, \\\n",
    "                                        station_names, arrival_times))\n",
    "    else:\n",
    "        if isadvance :\n",
    "            current_time = current_time - 180\n",
    "        # get the distances for all stations\n",
    "        walking_times = walking_distances[index_from_station[current_station],:]\n",
    "        # get stations in walking distance\n",
    "        close_stations = np.argwhere(walking_times<MAX_WALKING_TIME)\n",
    "        # remove station itself\n",
    "        close_stations = [i for i in close_stations.flatten().tolist()  \\\n",
    "                         if i!=index_from_station[current_station]]\n",
    "        # get the names of the stations\n",
    "        station_names = [station_from_index[i] for i in close_stations]\n",
    "        # get the estimated arrival times for all stations\n",
    "        departure_time = (current_time - walking_times[close_stations].flatten()).tolist()\n",
    "        # get the other information necessary\n",
    "        line_type = [None]*len(station_names)\n",
    "        arrival_times = [current_time]*len(station_names)\n",
    "        # return the tuples we want\n",
    "        walking_stops_tuples = list(zip(line_type, departure_time, \\\n",
    "                                        station_names, arrival_times))\n",
    "        \n",
    "    return walking_stops_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_walking_stations(current_station, current_time):\n",
    "#    coord_stat = df_stops.filter(df_stops['station_name'] == current_station).select('KOORDE','KOORDN').rdd.map(lambda x:(float(x[0]),float(x[1]))).collect()[0]\n",
    "#    interm = df_stops.rdd.map(lambda x: (x[0],euclidiandist(float(x[1]),coord_stat[0],float(x[2]),coord_stat[1])))\n",
    "#    #We want station that are 5 minutes away\n",
    "#    res = interm.filter(lambda x : x[1] <= 300)\n",
    "#    \n",
    "#    # return the tuples we want\n",
    "#    walking_stops_tuples = res.filter(lambda x : x[1] <= 900).filter(lambda x: x[0] != current_station).map(lambda x: (None,current_time,x[0],current_time + x[1])).collect()\n",
    "#    return walking_stops_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_stations(df, distance_df, stop_name, desired_time, mode,\\\n",
    "                                   allowed_timewindow=1800, isadvance = False):\n",
    "    \"\"\"\n",
    "    Get all stations accessible from a given point by either a SBB trip or by walking\n",
    "    \n",
    "    input: \n",
    "    \n",
    "        df :         df with structure as sbb_df\n",
    "        distance_df: df of a kind didok_df\n",
    "        stop_name:   string, name of the station we are heading to or from, when mode is forward for a fixed time of arrival, \\\n",
    "                     or anything else for fixed time of departure\n",
    "\n",
    "        desired_time: time in seconde (unix time)\n",
    "\n",
    "        allowed_timewindow: maximum time of waiting at a station in seconds\n",
    "    \n",
    "    output:\n",
    "        a tuple list of all accesible in the format: (type of train, departure time at current station,\n",
    "                                                       name of the next station, time of arrival at next station)\n",
    "        NB : if the trip is by walking the type of train is None\n",
    "\n",
    "    \"\"\"\n",
    "    df = df\\\n",
    "        .withColumn('ArrivalTimeScheduled', f.unix_timestamp(f.col(\"ArrivalTimeScheduled\"), \"dd.MM.yyyy HH:mm\"))\\\n",
    "        .withColumn('ArrivalTimeActual', f.unix_timestamp(f.col(\"ArrivalTimeActual\"), \"dd.MM.yyyy HH:mm\"))\\\n",
    "        .withColumn('DepartureTimeScheduled', f.unix_timestamp(f.col(\"DepartureTimeScheduled\"), \"dd.MM.yyyy HH:mm\"))\\\n",
    "        .withColumn('DepartureTimeActual', f.unix_timestamp(f.col(\"DepartureTimeActual\"), \"dd.MM.yyyy HH:mm\"))\n",
    "    if(mode == 'forward') :\n",
    "        in_station = df.filter(df['SkipStation'] == 'false').filter(df['DepartureTimeScheduled'] > desired_time).filter(df['DepartureTimeScheduled'] < desired_time + allowed_timewindow).filter(df['station_name'] == stop_name).select('TripId','DepartureTimeScheduled')\n",
    "        next_station = df.filter(df['SkipStation'] == 'false').select('StopName','TripId','ArrivalTimeScheduled','TransportType').na.fill(\"Unknown\")\n",
    "        both = next_station.filter(next_station['StopName'] != stop_name).filter(next_station['ArrivalTimeScheduled'] < desired_time + 28800).join(in_station,on = 'TripId')\n",
    "        res = both.filter(both['ArrivalTimeScheduled'] > both['DepartureTimeScheduled'] ).select('TransportType','DepartureTimeScheduled','StopName','ArrivalTimeScheduled')\n",
    "        tuples_train = res.rdd.map(lambda row:(row[0], row[1], row[2], row[3])).collect()\n",
    "    else :\n",
    "        # We divide the allowed time window by two in the case that the arrival time is fixed, assuming that tolerence for waiting in arrival point is lower that at departure \n",
    "        in_station = df.filter(df['SkipStation'] == 'false').filter(df['ArrivalTimeScheduled'] < desired_time).filter(df['ArrivalTimeScheduled'] > desired_time - allowed_timewindow/2).filter(df['station_name'] == stop_name).select('TripId','ArrivalTimeScheduled')\n",
    "\n",
    "        next_station = df.filter(df['SkipStation'] == 'false').select('StopName','TripId','DepartureTimeScheduled','TransportType').na.fill(\"Unknown\")\n",
    "\n",
    "        both = next_station.filter(next_station['StopName'] != stop_name).filter(next_station['DepartureTimeScheduled'] > desired_time - 28800).join(in_station,on = 'TripId')\n",
    "        res = both.filter(both['ArrivalTimeScheduled'] > both['DepartureTimeScheduled'] ).select('TransportType','DepartureTimeScheduled','StopName','ArrivalTimeScheduled')\n",
    "        tuples_train = res.rdd.map(lambda row:(row[0], row[1], row[2], row[3])).collect()\n",
    "    tuples_with_walking = get_walking_stations(stop_name, desired_time, mode, isadvance)\n",
    "    all_tuples = tuples_train + tuples_with_walking\n",
    "    \n",
    "    \n",
    "    return all_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deal with the fact that the time of arrival is not determinitic but a random variable. If we need to define it by a single value we decided to use the expectency, which is used to calculate the estimated time of arrival. The delay probability is used to find the probability for a train to arrive early enough that the user can safly catch the next train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_delay(station_name, line_id):\n",
    "    row = delays_df.loc[(delays_df.LINIEN_TEXT == line_id) & (delays_df.HALTESTELLEN_NAME==station_name)]\n",
    "    if row.shape[0]>0:\n",
    "        s = row['shape'].values[0]\n",
    "        loc = row['mean'].values[0]\n",
    "        scale = row['std'].values[0]\n",
    "        mean = stats.lognorm.mean(s, loc=loc, scale=scale)\n",
    "        return mean\n",
    "    else:\n",
    "        return 0 # average expected delay over dataset is 0, congrats SBB ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def get_delay_probability(station_name, line_id, delay):\n",
    "    row = delays_df.loc[(delays_df.LINIEN_TEXT == line_id) & (delays_df.HALTESTELLEN_NAME==station_name)]\n",
    "    if row.shape[0]>0:\n",
    "        # cdf parameters present, calcualte cdf value\n",
    "        s = row['shape'].values[0]\n",
    "        loc = row['mean'].values[0]\n",
    "        scale = row['std'].values[0]\n",
    "        return stats.lognorm.cdf(delay, s, loc=loc, scale=scale)\n",
    "    else:\n",
    "        # not present, resort to default\n",
    "        binvals = np.load(DATA_PATH+'default_delay.npy')\n",
    "        if delay>60:\n",
    "            return 1 - binvals[61]\n",
    "        p = 0\n",
    "        for i in range(int(delay+1)):\n",
    "            p += binvals[i]\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/stations_dict', 'rb') as handle:\n",
    "    stations_dict = pickle.load(handle)\n",
    "min_travel_times = np.load('./data/min_travel_times.npy')\n",
    "\n",
    "def get_heuristic(city_a,city_b):\n",
    "    '''\n",
    "    Calculates the heuristic of time in minutes between two city taking a train\n",
    "    '''\n",
    "    # try to find connection in our adjacency matrix calculated in Heuristic.ipynb\n",
    "    if city_a in stations_dict and city_b in stations_dict:\n",
    "        i = stations_dict[city_a]\n",
    "        j = stations_dict[city_b]\n",
    "        estimated_time = min_travel_times[i,j]\n",
    "        if estimated_time!=1440:\n",
    "            # estimated_time=1440: no possible connection was found when building the Heuristic adjacency matrix\n",
    "            return float(estimated_time)\n",
    "    \n",
    "    avg_speed = 1600\n",
    "    try :\n",
    "        df_a = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_a).collect()\n",
    "        x_a = float(df_a[0]['KOORDE'])\n",
    "        y_a = float(df_a[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_a,'is invalide')\n",
    "        return 0\n",
    "    try :\n",
    "        df_b = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_b).collect()\n",
    "        x_b = float(df_b[0]['KOORDE'])\n",
    "        y_b = float(df_b[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_b,'is invalide')\n",
    "        return 0\n",
    "    eucl_dist = math.sqrt((x_a-x_b)*(x_a-x_b)+ (y_a-y_b)*(y_a-y_b))\n",
    "    return eucl_dist/avg_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining useful classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step :\n",
    "    def __init__(self,departure_station,arrival_station, depature_time,arrival_time, train):\n",
    "        self.departure_station = departure_station\n",
    "        self.arrival_station = arrival_station\n",
    "        self.depature_time = depature_time\n",
    "        self.arrival_time = arrival_time\n",
    "        self.train = train\n",
    "    def _get(self) :\n",
    "        #print('From : ',self.departure_station,',to : ', self.arrival_station, ',departing at : ', self.depature_time,\n",
    "        #     'with train', self.train, '\\n')\n",
    "        return {'departure' : self.departure_station, 'destination' : self.arrival_station, \\\n",
    "                'time of departure' : datetime.fromtimestamp(abs(self.depature_time)).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "                'time of arrival' : datetime.fromtimestamp(abs(self.arrival_time)).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "                'type' : self.train}\n",
    "\n",
    "# Station keep each station and it's associated heuristic \n",
    "class Station :\n",
    "    def __init__(self,name, heuristic):\n",
    "        self.name = name\n",
    "        self.heuristic = heuristic\n",
    "    def _print(self) :\n",
    "        print('Station ',self.name,'with heursitic ', self.heuristic)\n",
    "\n",
    "# State describe a station visited at a certain time from a certain path, with a certain probability \n",
    "class State :\n",
    "    def __init__(self,station, eta, ps, previous_steps,last_train,pred_arrival_time):\n",
    "        # Name of the station at that state\n",
    "        self.station = station\n",
    "        \n",
    "        # Estimated time of arrival at that state. (in backward mode this is estimated time of departure)\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Probability to be at that state (given by probability to be at last state * probability to catch connection\n",
    "        #to previous state)\n",
    "        self.ps = ps\n",
    "        \n",
    "        # List of the step we took to get to that state\n",
    "        self.previous_steps = previous_steps\n",
    "        \n",
    "        # The linien_text of the last taken train\n",
    "        self.last_train = last_train\n",
    "        \n",
    "        # The predicted arrival time to that station (in backward mode this is predicted depature time of last transition)\n",
    "        self.pred_arrival_time = pred_arrival_time\n",
    "    def get_steps(self) :\n",
    "        steps_list = []\n",
    "        if (len(self.previous_steps) != 0):\n",
    "            for step in self.previous_steps :\n",
    "                steps_list.append(step._get())\n",
    "        else : print('Leave from home')\n",
    "        return steps_list\n",
    "    def __lt__ (self,other) :\n",
    "        return self.eta < other.eta\n",
    "    def __hash__ (self) :\n",
    "        return hash(self.eta)  \n",
    "    def _print(self) :\n",
    "        print('At',self.station.name,' the estimated time of arrival is ',self.eta\\\n",
    "              ,' with a probability of being here of ',self.ps, '\\n')\n",
    "        \n",
    "class End(Exception):\n",
    "    \"\"\"We found the right station\"\"\"\n",
    "    pass\n",
    "class Empty_queue(Exception):\n",
    "    \"\"\"Parameter where too restrictive, no path found and priority queue is empty\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementating the shortest path search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createstate(state,next_,destination,Pthresh,way):\n",
    "    \"\"\"Create a state resulting of a trip between station a and b :\n",
    "    Input : \n",
    "        - current state s at station a\n",
    "        - tuple containing the linien_text of the train t that goes from a to b, predicted\n",
    "        departure time at station a, predicted arrival time at station b and name of station b\n",
    "        - Final destination we are looking for and minimum probability we need. \n",
    "    Output :\n",
    "        - New State resulting from trip from a to b \"\"\"\n",
    "    linien_text = next_[0]\n",
    "    station_name = next_[2]\n",
    "    pred_departure = next_[1] \n",
    "    pred_arrival = next_[3]\n",
    "    # first we estimate the heuristic for this new station\n",
    "    heuristic = get_heuristic(station_name,destination)\n",
    "    station = Station(station_name,heuristic)\n",
    "    \n",
    " \n",
    "    if(linien_text != None) :\n",
    "        # If we go to the next station by train\n",
    "        \n",
    "        # get expected probability \n",
    "        Expected_delay = get_expected_delay(linien_text,station_name)\n",
    "        \n",
    "        if (way == 'forward') :\n",
    "            # Calculate the new ETA\n",
    "            ETA = Expected_delay*60 + heuristic*60 + pred_arrival\n",
    "             # Calculates the probability that the last train arrives early enough to catch the next one (3min changing time)\n",
    "            delay = pred_departure- state.pred_arrival_time - 3*60\n",
    "            Pboard = get_delay_probability(state.station.name,linien_text,delay/60)\n",
    "            #Calculate the probability of the state which is the probability of the last state * probability of having made\n",
    "            # it to the next trip on time\n",
    "            Ps = state.ps * Pboard\n",
    "\n",
    "            # Update the step list \n",
    "            new_step = Step(state.station.name,station_name,pred_departure,pred_arrival,linien_text) \n",
    "            Previous = state.previous_steps + [new_step]\n",
    "            return State(station,ETA,Ps,Previous,linien_text,pred_arrival)\n",
    "        else :\n",
    "            # Since the train departure time are assumed to be deterministic their is no delay of departure also eta is really estimated departure time\n",
    "            # in this way of calculation and must be negatuve as the priority list is selecting on smaller element\n",
    "            ETD = heuristic*60 - pred_departure\n",
    "             # Calculates the probability that the last train arrives early enough to catch the next one (3min changing time)\n",
    "            # NB here state.pred_arrival_time is actually the depature time of the next connection\n",
    "            delay = state.pred_arrival_time - pred_arrival\n",
    "            Pboard = get_delay_probability(state.station.name,linien_text,delay/60)\n",
    "            #Calculate the probability of the state which is the probability of the last state * probability of having made\n",
    "            # it to the next trip on time\n",
    "            Ps = state.ps * Pboard\n",
    "\n",
    "            # Update the step list \n",
    "            new_step = Step(station_name,state.station.name,pred_departure,pred_arrival,linien_text) \n",
    "            Previous = [new_step] + state.previous_steps \n",
    "            return State(station,ETD,Ps,Previous,linien_text,pred_departure)\n",
    "        \n",
    "        \n",
    "       \n",
    "    else : \n",
    "        # if we walked from the last station  \n",
    "        walking_time = pred_arrival - pred_departure \n",
    "        if (way == 'forward') :\n",
    "            ETA = state.eta - state.station.heuristic*60 + walking_time + heuristic*60\n",
    "            # if we walk we can leave when we want\n",
    "            Ps = state.ps\n",
    "            # Update the step list \n",
    "            new_step = Step(state.station.name,station_name,pred_departure,pred_arrival,'Walk')\n",
    "            Previous = state.previous_steps + [new_step]\n",
    "            return State(station,ETA,Ps,Previous,linien_text,pred_arrival)\n",
    "        else :\n",
    "            ETD = state.eta - state.station.heuristic*60 +  heuristic*60 + walking_time\n",
    "            # we assume that we must arrive 3 minute in advance or more to catch the train\n",
    "            Ps = state.ps\n",
    "            # Update the step list \n",
    "            new_step = Step(station_name,state.station.name,pred_departure,pred_arrival,'Walk')\n",
    "            Previous = [new_step] + state.previous_steps\n",
    "            return State(station,ETD,Ps,Previous,linien_text,pred_departure)\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firststep(From, To, t, Pthresh,way):\n",
    "    t = float(time.mktime(datetime.strptime(t, \"%d.%m.%Y %H:%M\").timetuple()))\n",
    "    start_heuristic = get_heuristic(From,To)\n",
    "    pqueue = PriorityQueue()\n",
    "    pqueue.put((float('inf'),\"empty_queue\"))\n",
    "    if (way == 'forward') :\n",
    "        current_station = Station(From,start_heuristic)\n",
    "        start_state = State(current_station,start_heuristic*60+t,1.0,[],\"starting\",t)\n",
    "        pqueue.put((start_state.eta,start_state))\n",
    "    else :\n",
    "        current_station = Station(To,start_heuristic)\n",
    "        start_state = State(current_station,start_heuristic*60-t,1.0,[],\"starting\",t)\n",
    "        pqueue.put((start_state.eta,start_state))\n",
    "    visited = visited_nodes()\n",
    "    visited.update(start_state,way)\n",
    "    return visited,pqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_step(priortity_list,Pthresh,destination,visited,way,reduced_df) :\n",
    "    \"\"\"For the first state in the priority_list find all possible next state and insert them into the priortity list \n",
    "    if their probability is highy<Ser than Pthresh\"\"\"\n",
    "    current_state = priortity_list.get()[1]\n",
    "    if (type(current_state) == str) :\n",
    "        raise Empty_queue(\"error\")\n",
    "    #print(current_state.station.name,nice_time(current_state.eta),current_state.ps,current_state.last_train,len(current_state.previous_steps))\n",
    "    if (current_state.station.name == destination):\n",
    "        raise End(8,current_state)\n",
    "    # Get all stations to which we can go from current state\n",
    "    # Let's assume that getpossibletrip returns a list of tuple like \n",
    "    # (linien_text,next_station_name,predicted_arrival_time_current_station,predicted_departure_time, predicted_arrival_time) \n",
    "    # for each possible new trip. Predicted_departure_time is the predicted departure time at current state\n",
    "    # predicted_arrival_time the predicted arrival time in the reachable station\n",
    "    # If we are walking train_id is None, departure is the arrival time of last trip\n",
    "    # and arrival is departure time + estimation for walking time. \n",
    "    if (way == 'forward'):\n",
    "        possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way)\n",
    "    else :\n",
    "        if(current_state.last_train != \"starting\"):\n",
    "            # if we have a connections to catch and we are walking we should arrive 3 minutes in advance \n",
    "            possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way,isadvance = True)\n",
    "        else :\n",
    "            # if we are walking to destination we can arrive at desired time  \n",
    "            possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way)\n",
    "        \n",
    "    # For each next station, lets create the next state and add it to the Priority Queue\n",
    "    for next_ in possible_next_stops :\n",
    "        #print(next_[2],'leaving at ',nice_time(next_[1]), 'arriving at',nice_time(next_[3]),'using',next_[0])\n",
    "        if (current_state.last_train == None and next_[0] == None) :\n",
    "            # Here we want to avoid to do twice a trip by walking\n",
    "            continue\n",
    "        n_state = createstate(current_state,next_,destination,Pthresh,way)\n",
    "        if n_state.ps > Pthresh and visited.update(n_state,way) :\n",
    "            priortity_list.put((n_state.eta,n_state))\n",
    "    return priortity_list, visited\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visited nodes\n",
    "We want to model the set of visited nodes in a way that there are duplicates in the visited nodes only if the node has a higher probability of arriving there in a slower time. In all other cases only the fastest achieved node is saved in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_tuple_from_node(node):\n",
    "        return (node.station.name, node.eta, node.ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visited_nodes as a set of tuples, containing: (station, visit-time, certainity)\n",
    "class visited_nodes:\n",
    "    def __init__(self, initial_set=set([])):\n",
    "        self.nodes = initial_set\n",
    "    def update(self, new_node,way):\n",
    "        old_nodes = self.previous_visits(new_node)\n",
    "        new_node_tup = create_tuple_from_node(new_node)\n",
    "        \n",
    "        if len(old_nodes) == 0: #case when the node has not been explored yet.\n",
    "            self.add_to_visited(new_node_tup)\n",
    "            return True\n",
    "         \n",
    "        else: #case when the node has been explored and multiple optimal values are in the set\n",
    "            added = False\n",
    "            for n in old_nodes: #iterate through nodes and compare to new node\n",
    "                if (way == 'forward') :\n",
    "                    if self.compare_nodes_2_forward(n, new_node_tup): #node is added if better/equal than any node and replaces worse nodes\n",
    "                        added = True\n",
    "                else :\n",
    "                    if self.compare_nodes_2_backward(n, new_node_tup): #node is added if better/equal than any node and replaces worse nodes\n",
    "                        added = True\n",
    "            self.compare_in_set(new_node,way)\n",
    "            return added\n",
    "            \n",
    "    '''previous_visits takes a node and compares it to the already existing set of nodes that have been visited.\n",
    "        If a node has been visited before, the function hands out the previous visits in a list'''\n",
    "    def previous_visits(self, new_node):\n",
    "        return list(filter(lambda x: x[0] == new_node.station.name, self.nodes))\n",
    "    \n",
    "    '''add_to_visited takes a new node and adds it to the set of visited nodes'''\n",
    "    def add_to_visited(self, new_node_tup):\n",
    "        self.nodes.add(new_node_tup)\n",
    "        return None\n",
    "    \n",
    "    '''replace_old is used when a better node (higher probability and faster) appears. It takes a new node and adds\n",
    "        it to the set of visited nodes, while deleting the old one'''\n",
    "    def replace_old(self, new_node, old_node):\n",
    "        self.add_to_visited(new_node)\n",
    "        if old_node in self.nodes:\n",
    "            self.nodes.remove(old_node)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    '''takes two nodes and compares them according to the arrival time and probability. If a node is in some way\n",
    "        better than the existing it is stored. The function returns a boolean which indicates whether the value \n",
    "        has been stored (important to know for updating priority queue)'''\n",
    "    def compare_nodes_2_forward(self, node1, node2):\n",
    "    # Compare node by estimated time of arrival in which a lower eta is a fastest way\n",
    "        if node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is faster and has a higher proba\n",
    "            self.replace_old(node2, node1) #we replace the slow and improbable node\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] > node2[2]: #the node2 is only faser, but less certain\n",
    "            self.add_to_visited(node2) # add to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] < node2[2]: #the node2 is slower but more certain\n",
    "            self.add_to_visited(node2) #add it to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] == node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        elif node1[1] == node2[1] and node1[2] < node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False #the node2 is neither more certain nor faster, we drop it.\n",
    "    def compare_nodes_2_backward(self, node1, node2):\n",
    "        # Compare node by estimated time of departure in which a bigger etd is a fastest way\n",
    "        if node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is faster and has a higher proba\n",
    "            self.replace_old(node2, node1) #we replace the slow and improbable node\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] > node2[2]: #the node2 is only faser, but less certain\n",
    "            self.add_to_visited(node2) # add to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is slower but more certain\n",
    "            self.add_to_visited(node2) #add it to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] == node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        elif node1[1] == node2[1] and node1[2] < node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False #the node2 is neither more certain nor faster, we drop it.\n",
    "            \n",
    "    def compare_in_set(self, new_node,way):\n",
    "        old_nodes = self.previous_visits(new_node)\n",
    "        for n in old_nodes:\n",
    "            for m in old_nodes:\n",
    "                if (way == 'forward'):\n",
    "                    self.compare_nodes_2_forward(n, m)\n",
    "                else :\n",
    "                    self.compare_nodes_2_backward(n, m)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(From,To,At,P,way):\n",
    "    steps = None\n",
    "    # initate the queue \n",
    "    visited,queue = firststep(From,To,At,P,way)\n",
    "    \n",
    "    # load the Data for the day of the trip as well as one day before/after to account for midnight trip.\n",
    "    t = datetime.strptime(At, \"%d.%m.%Y %H:%M\").timetuple()\n",
    "    if (way == 'forward') :\n",
    "        path1 = '/datasets/sbb/{}/{:02d}/{}-{:02d}-{:02d}istdaten.csv.bz2'.format(t[0],t[1],t[0],t[1],t[2])\n",
    "        path2 = '/datasets/sbb/{}/{:02d}/{}-{:02d}-{:02d}istdaten.csv.bz2'.format(t[0],t[1],t[0],t[1],t[2] + 1)\n",
    "    else :\n",
    "        path1 = '/datasets/sbb/{}/{:02d}/{}-{:02d}-{:02d}istdaten.csv.bz2'.format(t[0],t[1],t[0],t[1],t[2] - 1)\n",
    "        path2 = '/datasets/sbb/{}/{:02d}/{}-{:02d}-{:02d}istdaten.csv.bz2'.format(t[0],t[1],t[0],t[1],t[2])\n",
    "    swiss_data = spark.read.csv([path1,path2], header=True, sep=\";\").cache()\n",
    "    istdaten = swiss_data.join(stops_filter, swiss_data.HALTESTELLEN_NAME == stops_filter.station_name, 'inner')\n",
    "    \n",
    "    traduction = 'TripDate string, TripId string, OperatorId string, OperatorAbbrv string, OperatorName string, ProductId string, LineId string, LineType string, UmlaufId string, TransportType string, AdditionalTrip boolean, FailedTrip boolean, BPUIC string, StopName string, ArrivalTimeScheduled string, ArrivalTimeActual string, ArrivalTimeActualStatus string,     DepartureTimeScheduled string, DepartureTimeActual string, DepartureTimeActualStatus string, SkipStation boolean'\n",
    "    traduction = list(map(lambda x: x.split()[0],traduction.split(',')))\n",
    "\n",
    "    for german, english in zip(istdaten.columns, traduction):\n",
    "        istdaten = istdaten.withColumnRenamed(german, english)\n",
    "    \n",
    "    # Running the query until the final station is found \n",
    "    while True:\n",
    "        try:\n",
    "            if (way =='forward'):\n",
    "                queue,visited = new_step(queue,P,To,visited,way,istdaten)\n",
    "            else :\n",
    "                queue,visited = new_step(queue,P,From,visited,way,istdaten)\n",
    "        except End as end: \n",
    "            # We found the soltution\n",
    "            final_state = end.args[1]\n",
    "            steps = pd.DataFrame(final_state.get_steps())\n",
    "            break\n",
    "        except Empty_queue:\n",
    "            print('No way was found with this probability threshold, try again with a lower threshold or stay home')\n",
    "            break\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few run to try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_time(t):\n",
    "    \"\"\"Useful for seeing time for debugging\"\"\"\n",
    "    return datetime.fromtimestamp(abs(t)).strftime(\"%d.%m.%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 5.866852414608002mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure</th>\n",
       "      <th>destination</th>\n",
       "      <th>time of arrival</th>\n",
       "      <th>time of departure</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZÃ¼rich Tiefenbrunnen</td>\n",
       "      <td>ZÃ¼rich HB</td>\n",
       "      <td>2017-10-17 17:59:00</td>\n",
       "      <td>2017-10-17 17:53:00</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZÃ¼rich HB</td>\n",
       "      <td>ZÃ¼rich, Central</td>\n",
       "      <td>2017-10-17 18:05:18</td>\n",
       "      <td>2017-10-17 17:59:59</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              departure      destination      time of arrival  \\\n",
       "0  ZÃ¼rich Tiefenbrunnen        ZÃ¼rich HB  2017-10-17 17:59:00   \n",
       "1             ZÃ¼rich HB  ZÃ¼rich, Central  2017-10-17 18:05:18   \n",
       "\n",
       "     time of departure  type  \n",
       "0  2017-10-17 17:53:00     S  \n",
       "1  2017-10-17 17:59:59  Walk  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "steps = main('ZÃ¼rich Tiefenbrunnen','ZÃ¼rich, Central','17.10.2017 17:45',0.9,'forward')\n",
    "\n",
    "end = time.time()\n",
    "print('took {}mins'.format((end - start)/60))\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1.059355584780375mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure</th>\n",
       "      <th>destination</th>\n",
       "      <th>time of arrival</th>\n",
       "      <th>time of departure</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZÃ¼rich Tiefenbrunnen</td>\n",
       "      <td>ZÃ¼rich, Wildbachstrasse</td>\n",
       "      <td>2017-10-17 17:49:35</td>\n",
       "      <td>2017-10-17 17:45:00</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZÃ¼rich, Wildbachstrasse</td>\n",
       "      <td>ZÃ¼rich, HÃ¶schgasse</td>\n",
       "      <td>2017-10-17 17:58:00</td>\n",
       "      <td>2017-10-17 17:56:00</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 departure              destination      time of arrival  \\\n",
       "0     ZÃ¼rich Tiefenbrunnen  ZÃ¼rich, Wildbachstrasse  2017-10-17 17:49:35   \n",
       "1  ZÃ¼rich, Wildbachstrasse       ZÃ¼rich, HÃ¶schgasse  2017-10-17 17:58:00   \n",
       "\n",
       "     time of departure     type  \n",
       "0  2017-10-17 17:45:00     Walk  \n",
       "1  2017-10-17 17:56:00  Unknown  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "steps = main('ZÃ¼rich Tiefenbrunnen','ZÃ¼rich, HÃ¶schgasse','17.10.2017 17:45',0.7,'forward')\n",
    "\n",
    "end = time.time()\n",
    "print('took {}mins'.format((end - start)/60))\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 2.2776575803756716mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure</th>\n",
       "      <th>destination</th>\n",
       "      <th>time of arrival</th>\n",
       "      <th>time of departure</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZÃ¼rich Tiefenbrunnen</td>\n",
       "      <td>ZÃ¼rich, Wildbachstrasse</td>\n",
       "      <td>2017-10-17 17:53:00</td>\n",
       "      <td>2017-10-17 17:48:24</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZÃ¼rich, Wildbachstrasse</td>\n",
       "      <td>ZÃ¼rich, HÃ¶schgasse</td>\n",
       "      <td>2017-10-17 17:58:00</td>\n",
       "      <td>2017-10-17 17:56:00</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 departure              destination      time of arrival  \\\n",
       "0     ZÃ¼rich Tiefenbrunnen  ZÃ¼rich, Wildbachstrasse  2017-10-17 17:53:00   \n",
       "1  ZÃ¼rich, Wildbachstrasse       ZÃ¼rich, HÃ¶schgasse  2017-10-17 17:58:00   \n",
       "\n",
       "     time of departure     type  \n",
       "0  2017-10-17 17:48:24     Walk  \n",
       "1  2017-10-17 17:56:00  Unknown  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "steps = main('ZÃ¼rich Tiefenbrunnen','ZÃ¼rich, HÃ¶schgasse','17.10.2017 18:05',0.7,'backward')\n",
    "\n",
    "end = time.time()\n",
    "print('took {}mins'.format((end - start)/60))\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB :* Since computation is quite expensive and long a exemple of vizualization and result if offered in the Vizualisation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/stations', 'rb') as stations_file:\n",
    "     stations_list = pickle.load(stations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_desired_arrival(destination, departure, dt, p):\n",
    "    # here, call the scheduler and return the obtained dataframe\n",
    "    return main(departure, destination, dt, p, 'backward')\n",
    "def cb_desired_departure(destination, departure, dt, p):\n",
    "    # here, call the scheduler and return the obtained dataframe\n",
    "    return main(departure, destination, dt, p, 'forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook import notebookapp\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "notebook_url = servers[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script src=\"http://10.90.38.18:35812/autoload.js?bokeh-autoload-element=1003&bokeh-absolute-url=http://10.90.38.18:35812&resources=none\" id=\"1003\"></script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "6824255420504323b92ccb710fcb903e"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import curdoc\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.layouts import column, row, layout\n",
    "from bokeh.models.layouts import Column\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import DatePicker, Button, Select, RadioButtonGroup, \\\n",
    "                            Slider, AutocompleteInput, DataTable, DateFormatter, TableColumn, Paragraph\n",
    "from datetime import date\n",
    "from datetime import timedelta as td\n",
    "from datetime import datetime\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "from bokeh.application import Application\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "def modify_doc(doc):\n",
    "\n",
    "    #crnt_date=dt.now()\n",
    "    # datetime stuff\n",
    "    dt_pckr=DatePicker(title='Date',min_date=date(2017,1,1),max_date=date.today(), value=date(2017, 10, 17))\n",
    "    hours = Select(title=\"Hour:\", value='12', options=[str(i) for i in range(24)])\n",
    "    mins = Select(title=\"Min:\", value='00', options=['{:02}'.format(i) for i in range(60)])\n",
    "    # location stuff\n",
    "    start = AutocompleteInput(title=\"Start:\", completions=stations_list)\n",
    "    destination = AutocompleteInput(title=\"Destination:\", completions=stations_list)\n",
    "    direction = RadioButtonGroup(labels=[\"Arrival At\", \"Departure At\"], active=0)\n",
    "    # probability stuff\n",
    "    certainty_slider = Slider(start=0, end=1, value=0.7, step=.01, title=\"Certainty of making connections\")\n",
    "    # outputting\n",
    "    # table\n",
    "    frame = pd.DataFrame({'departure':[], 'destination':[], 'time of departure':[], 'time of arrival':[], 'type':[]})\n",
    "    Columns = [TableColumn(field=Ci, title=Ci) for Ci in frame.columns] # bokeh columns\n",
    "    init_source = ColumnDataSource(frame)\n",
    "    data_table = DataTable(columns=Columns, source=init_source) # bokeh table\n",
    "    # status text\n",
    "    status_text = Paragraph(text = 'Welcome to our scheduler! Select your trip and hit Go!', width = 400)\n",
    "    \n",
    "    \n",
    "    #button\n",
    "    button = Button(label=\"Go\", button_type=\"success\")\n",
    "    def button_click():\n",
    "        if destination.value in stations_list and start.value in stations_list:\n",
    "            date_string = dt_pckr.value.strftime('%d.%m.%Y')\n",
    "            datetime_string = date_string + ' {}:{}'.format(hours.value, mins.value)\n",
    "            if direction.active ==0:\n",
    "                r = cb_desired_arrival(destination.value, start.value, datetime_string, certainty_slider.value)\n",
    "            else:\n",
    "                r = cb_desired_departure(destination.value, start.value, datetime_string, certainty_slider.value)\n",
    "            data_table.source.data = ColumnDataSource(r).data\n",
    "            status_text.text = 'Here is your connection. You can select another one.'\n",
    "        elif destination.value in stations_list:\n",
    "            status_text.text = 'You picked a wrong departure station'\n",
    "        else:\n",
    "            status_text.text = 'You picked a wrong destination station'\n",
    "\n",
    "\n",
    "    #dt_pckr_strt.on_change('value',callback)\n",
    "    button.on_click(button_click)\n",
    "\n",
    "    doc.add_root(layout([[status_text],\n",
    "                         [direction],\n",
    "                         [dt_pckr, row(hours, mins, width=200)],\n",
    "                         [start, destination],\n",
    "                         [certainty_slider, button],\n",
    "                         [data_table]]))\n",
    "\n",
    "app = Application(FunctionHandler(modify_doc))\n",
    "show(app, notebook_url=notebook_url[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
