{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://iccluster042.iccluster.epfl.ch:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.0.0-78</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sbb2-mnovakov</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe36c874cf8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from queue import *\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import time\n",
    "#from geopy.distance import distance as geo_dist\n",
    "import scipy.stats\n",
    "from bisect import bisect_right\n",
    "import getpass\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from heapq import *\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName('sbb2-{0}'.format(getpass.getuser())) \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.port.maxRetries', '100') \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will build small toy example to discuss optimality of our algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will ask our algorithm to find optimal path between A and B, in forward manner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Filter\n",
    "We made small map of several stations\n",
    "\n",
    "First, we filter on only the stations in a 10km radius around node A. This allows for computation in \"reasonable\" time on the cluster\n",
    "\n",
    "**For further analysis, it is just important to note that B to D distance is 400m and we consider this distance as walkable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_squared(n1,e1, n2, e2):\n",
    "    '''Calculates the euclidean distance between two points'''\n",
    "    eucl_dist2 = ((n1-n2)*(n1-n2)+ (e1-e2)*(e1-e2))\n",
    "    return eucl_dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_zurich = (0, 0)\n",
    "\n",
    "koord_station_names = [\"A\", \"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"L\",\"M\"]\n",
    "KOORDEs = [0, 5000, 1000, 4600, -1000, -2000, 4600, 4600, 0, 10000, 5000, 100]\n",
    "KOORDNs = [0, 0, -1000, 0, -1000, -2000, 1300, 2300, -1250, 10000, 100, 0]\n",
    "\n",
    "df_stops = spark.createDataFrame(zip(koord_station_names, KOORDEs, KOORDNs), schema=[\"station_name\", \"KOORDE\", \"KOORDN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.withColumn('dist2', distance_squared(coords_zurich[1], coords_zurich[0], df_stops.KOORDN, df_stops.KOORDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = df_stops.filter(df_stops.dist2<=10000**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+--------+\n",
      "|station_name|KOORDE|KOORDN|   dist2|\n",
      "+------------+------+------+--------+\n",
      "|           A|     0|     0|       0|\n",
      "|           B|  5000|     0|25000000|\n",
      "|           C|  1000| -1000| 2000000|\n",
      "|           D|  4600|     0|21160000|\n",
      "|           E| -1000| -1000| 2000000|\n",
      "|           F| -2000| -2000| 8000000|\n",
      "|           G|  4600|  1300|22850000|\n",
      "|           H|  4600|  2300|26450000|\n",
      "|           I|     0| -1250| 1562500|\n",
      "|           L|  5000|   100|25010000|\n",
      "|           M|   100|     0|   10000|\n",
      "+------------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stops.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing isdaten df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+----------------+-----------+-------------+\n",
      "|HALTESTELLEN_NAME|    ABFAHRTSZEIT|    ANKUNFTSZEIT|FAHRT_BEZEICHNER|LINIEN_TEXT|DURCHFAHRT_TF|\n",
      "+-----------------+----------------+----------------+----------------+-----------+-------------+\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:59|               1|        IAD|        false|\n",
      "|                D|17.10.2018 16:11|17.10.2018 16:10|               1|        IAD|        false|\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:58|               2|        IAB|        false|\n",
      "|                B|17.10.2018 16:01|17.10.2018 16:00|               2|        IAB|        false|\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:58|               3|        IAC|        false|\n",
      "|                C|17.10.2018 15:26|17.10.2018 15:25|               3|        IAC|        false|\n",
      "|                B|17.10.2018 16:11|17.10.2018 16:10|               4|       IBCI|        false|\n",
      "|                C|17.10.2018 15:35|17.10.2018 15:30|               4|       IBCI|        false|\n",
      "|                I|17.10.2018 15:20|            Null|               4|       IBCI|        false|\n",
      "|                E|17.10.2018 15:00|17.10.2018 14:59|               5|        IAD|        false|\n",
      "|                F|17.10.2018 15:49|17.10.2018 15:50|               5|        IEF|        false|\n",
      "|                D|17.10.2018 16:13|17.10.2018 16:11|               6|        IEF|        false|\n",
      "|                G|17.10.2018 16:45|17.10.2018 16:43|               6|       IDGH|        false|\n",
      "|                H|17.10.2018 16:55|17.10.2018 16:50|               6|       IDGH|        false|\n",
      "|                D|17.10.2018 20:00|17.10.2018 19:59|               7|       IDGH|        false|\n",
      "|                A|17.10.2018 21:11|17.10.2018 21:10|               7|        IAD|        false|\n",
      "|                B|17.10.2018 20:35|17.10.2018 19:58|               8|        IAD|        false|\n",
      "|                A|17.10.2018 20:20|17.10.2018 21:00|               8|        IAB|        false|\n",
      "|                C|17.10.2018 20:00|17.10.2018 19:58|               9|        IAB|        false|\n",
      "|                A|17.10.2018 20:26|17.10.2018 20:25|               9|        IAC|        false|\n",
      "|                I|17.10.2018 21:11|17.10.2018 21:10|              10|        IAC|        false|\n",
      "|                C|17.10.2018 20:35|17.10.2018 20:30|              10|       IBCI|        false|\n",
      "|                B|17.10.2018 20:20|            Null|              10|       IBCI|        false|\n",
      "|                F|17.10.2018 20:00|17.10.2018 19:59|              11|       IBCI|        false|\n",
      "|                E|17.10.2018 20:49|17.10.2018 20:50|              11|        IAD|        false|\n",
      "|                H|17.10.2018 21:13|17.10.2018 21:11|              12|        IEF|        false|\n",
      "|                G|17.10.2018 21:45|17.10.2018 21:43|              12|        IEF|        false|\n",
      "|                D|17.10.2018 21:55|17.10.2018 21:50|              12|       IDGH|        false|\n",
      "+-----------------+----------------+----------------+----------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sbb_station_names = [\"A\", \"D\", \"A\", \"B\", \"A\", \"C\", \"B\", \"C\", \"I\", \"E\", \"F\", \"D\", \"G\", \"H\", \\\n",
    "                     \"D\", \"A\", \"B\", \"A\", \"C\", \"A\", \"I\", \"C\", \"B\", \"F\", \"E\", \"H\", \"G\", \"D\"]\n",
    "sbb_departure_times = [\"17.10.2018 15:00\", \"17.10.2018 16:11\", \"17.10.2018 15:00\", \"17.10.2018 16:01\", \"17.10.2018 15:00\",\\\n",
    "                   \"17.10.2018 15:26\", \"17.10.2018 16:11\", \"17.10.2018 15:35\", \"17.10.2018 15:20\", \"17.10.2018 15:00\",\\\n",
    "                       \"17.10.2018 15:49\", \"17.10.2018 16:13\", \"17.10.2018 16:45\", \"17.10.2018 16:55\",\n",
    "                      \"17.10.2018 20:00\", \"17.10.2018 21:11\", \"17.10.2018 20:35\", \"17.10.2018 20:20\", \"17.10.2018 20:00\",\\\n",
    "                   \"17.10.2018 20:26\", \"17.10.2018 21:11\", \"17.10.2018 20:35\", \"17.10.2018 20:20\", \"17.10.2018 20:00\",\\\n",
    "                       \"17.10.2018 20:49\", \"17.10.2018 21:13\", \"17.10.2018 21:45\", \"17.10.2018 21:55\"]\n",
    "\n",
    "sbb_arrival_times = [\"17.10.2018 14:59\", \"17.10.2018 16:10\", \"17.10.2018 14:58\", \"17.10.2018 16:00\", \"17.10.2018 14:58\",\\\n",
    "                 \"17.10.2018 15:25\", \"17.10.2018 16:10\", \"17.10.2018 15:30\", \"Null\", \"17.10.2018 14:59\", \\\n",
    "                     \"17.10.2018 15:50\", \"17.10.2018 16:11\", \"17.10.2018 16:43\", \"17.10.2018 16:50\", \\\n",
    "                     \"17.10.2018 19:59\", \"17.10.2018 21:10\", \"17.10.2018 19:58\", \"17.10.2018 21:00\", \"17.10.2018 19:58\",\\\n",
    "                 \"17.10.2018 20:25\", \"17.10.2018 21:10\", \"17.10.2018 20:30\", \"Null\", \"17.10.2018 19:59\", \\\n",
    "                     \"17.10.2018 20:50\", \"17.10.2018 21:11\", \"17.10.2018 21:43\", \"17.10.2018 21:50\"]\n",
    "\n",
    "sbb_skipstop = [\"false\"]*len(sbb_station_names)\n",
    "sbb_trip_ids = [1,1,2,2,3,3,4,4,4,5,5,6,6,6,7,7,8,8,9,9,10,10,10,11,11,12,12,12]\n",
    "p_user = 0.75\n",
    "probs = [0.9, 0.7, 0.8, 0.95, 0.99, 0.8]\n",
    "sbb_line_type = [\"IAD\", \"IAD\", \"IAB\", \"IAB\", \"IAC\", \"IAC\", \"IBCI\", \"IBCI\", \"IBCI\", \"IAD\", \"IEF\",\"IEF\",\"IDGH\",\"IDGH\",\"IDGH\"]*2\n",
    "\n",
    "swiss_data = spark.createDataFrame(zip(sbb_station_names, sbb_departure_times, sbb_arrival_times, sbb_trip_ids, sbb_line_type, sbb_skipstop)\\\n",
    "                                 , schema=[\"HALTESTELLEN_NAME\", \"ABFAHRTSZEIT\", \"ANKUNFTSZEIT\", \"FAHRT_BEZEICHNER\", \"LINIEN_TEXT\", \"DURCHFAHRT_TF\"])\n",
    "swiss_data.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table = df_stops.join(swiss_data, swiss_data.HALTESTELLEN_NAME == df_stops.station_name, 'inner').persist()\n",
    "df_stops = cross_table.select('station_name','KOORDE','KOORDN').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = cross_table.select('station_name','KOORDE','KOORDN').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|station_name|\n",
      "+------------+\n",
      "|           F|\n",
      "|           E|\n",
      "|           B|\n",
      "|           D|\n",
      "|           C|\n",
      "|           A|\n",
      "|           G|\n",
      "|           I|\n",
      "|           H|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_filter = df_stops.select('station_name')\n",
    "stops_filter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note from here that from A to B starting from 14:59, three routes are possible**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A-B directly, A-D-B due to acceptable walk between D and B, and A-C-B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**They take 60, 70+walk and 70 min respectively**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINIEN_TEXT</th>\n",
       "      <th>HALTESTELLEN_NAME</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IAD</td>\n",
       "      <td>A</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IAB</td>\n",
       "      <td>A</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IAC</td>\n",
       "      <td>A</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBCI</td>\n",
       "      <td>I</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBCI</td>\n",
       "      <td>C</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IEF</td>\n",
       "      <td>E</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IDGH</td>\n",
       "      <td>D</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IDGH</td>\n",
       "      <td>G</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LINIEN_TEXT HALTESTELLEN_NAME  prob\n",
       "0         IAD                 A  0.90\n",
       "1         IAB                 A  0.70\n",
       "2         IAC                 A  0.80\n",
       "3        IBCI                 I  0.95\n",
       "4        IBCI                 C  0.95\n",
       "5         IEF                 E  0.99\n",
       "6        IDGH                 D  0.80\n",
       "7        IDGH                 G  0.80"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = [0.9, 0.7, 0.8, 0.95, 0.95, 0.99, 0.8, 0.8]\n",
    "line_types = [\"IAD\", \"IAB\", \"IAC\", \"IBCI\", \"IBCI\", \"IEF\", \"IDGH\", \"IDGH\"]\n",
    "koord_station_names = [\"A\", \"A\", \"A\", \"I\", \"C\", \"E\", \"D\", \"G\"]#[\"D\", \"B\", \"C\", \"B\",\"C\",\"F\",\"G\",\"H\"]\n",
    "\n",
    "delays_df = pd.DataFrame(zip(line_types, koord_station_names, prob)\\\n",
    "                                 , columns=[\"LINIEN_TEXT\", \"HALTESTELLEN_NAME\", \"prob\"])\n",
    "delays_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that probabilities A-B directly 0.7, A-D-B due to acceptable walk between D and B 0.9, and A-C-B 0.8*0.95 = 0.76**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "We now want to read data from the sbb files and extract usefull information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find station accessible by walking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds stations in proximity of station of interest. We used 5 minute as an upperbound on the time of walking. Distance is computed as simply the euclidian distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidiandist(x_a,x_b,y_a,y_b):\n",
    "    # We assumed that average speed of the user is of 5km/h\n",
    "    avg_speed = 1.388889\n",
    "    eucl_dist = math.sqrt((x_a-x_b)*(x_a-x_b)+ (y_a-y_b)*(y_a-y_b))\n",
    "    return eucl_dist/avg_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, load all the necessary data\n",
    "import pickle\n",
    "with open('./data/station_from_index_testing.pkl', 'rb') as handle:\n",
    "    station_from_index = pickle.load(handle)\n",
    "with open('./data/index_from_station_testing.pkl', 'rb') as handle:\n",
    "    index_from_station = pickle.load(handle)\n",
    "walking_distances = np.load('./data/walking_distances_testing.npy')\n",
    "walking_distances = np.sqrt(walking_distances)\n",
    "\n",
    "# definition of the maximum walking time\n",
    "MAX_WALKING_TIME = 10*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walking_stations(current_station, current_time, way, isadvance):\n",
    "    if way == 'forward':\n",
    "        # get the distances for all stations\n",
    "        walking_times = walking_distances[index_from_station[current_station],:]\n",
    "        # get stations in walking distance\n",
    "        close_stations = np.argwhere(walking_times<MAX_WALKING_TIME)\n",
    "        # remove station itself\n",
    "        close_stations = [i for i in close_stations.flatten().tolist()  \\\n",
    "                         if i!=index_from_station[current_station]]\n",
    "        # get the names of the stations\n",
    "        station_names = [station_from_index[i] for i in close_stations]\n",
    "        # get the estimated arrival times for all stations\n",
    "        arrival_times = (walking_times[close_stations].flatten() + current_time).tolist()\n",
    "        # get the other information necessary\n",
    "        line_type = [None]*len(station_names)\n",
    "        departure_time = [current_time]*len(station_names)\n",
    "\n",
    "\n",
    "        # return the tuples we want\n",
    "        walking_stops_tuples = list(zip(line_type, departure_time, \\\n",
    "                                        station_names, arrival_times))\n",
    "    else:\n",
    "        if isadvance :\n",
    "            current_time = current_time - 180\n",
    "        # get the distances for all stations\n",
    "        walking_times = walking_distances[index_from_station[current_station],:]\n",
    "        # get stations in walking distance\n",
    "        close_stations = np.argwhere(walking_times<MAX_WALKING_TIME)\n",
    "        # remove station itself\n",
    "        close_stations = [i for i in close_stations.flatten().tolist()  \\\n",
    "                         if i!=index_from_station[current_station]]\n",
    "        # get the names of the stations\n",
    "        station_names = [station_from_index[i] for i in close_stations]\n",
    "        # get the estimated arrival times for all stations\n",
    "        departure_time = (current_time - walking_times[close_stations].flatten()).tolist()\n",
    "        # get the other information necessary\n",
    "        line_type = [None]*len(station_names)\n",
    "        arrival_times = [current_time]*len(station_names)\n",
    "        # return the tuples we want\n",
    "        walking_stops_tuples = list(zip(line_type, departure_time, \\\n",
    "                                        station_names, arrival_times))\n",
    "        \n",
    "    return walking_stops_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1000, 'D', 1400.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_walking_stations('B', 1000, \"forward\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 600.0, 'B', 1000)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_walking_stations('D', 1000, \"backward\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_possible_stations(df, distance_df, stop_name, desired_time, mode,\\\n",
    "                                   allowed_timewindow=1800, isadvance = False):\n",
    "    \"\"\"\n",
    "    Get all stations accessible from a given point by either a SBB trip or by walking\n",
    "    \n",
    "    input: \n",
    "    \n",
    "        df :         df with structure as sbb_df\n",
    "        distance_df: df of a kind didok_df\n",
    "        stop_name:   string, name of the station we are heading to or from, when mode is forward for a fixed time of arrival, \\\n",
    "                     or anything else for fixed time of departure\n",
    "\n",
    "        desired_time: time in seconde (unix time)\n",
    "\n",
    "        allowed_timewindow: maximum time of waiting at a station in seconds\n",
    "    \n",
    "    output:\n",
    "        a tuple list of all accesible in the format: (type of train, departure time at current station,\n",
    "                                                       name of the next station, time of arrival at next station)\n",
    "        NB : if the trip is by walking the type of train is None\n",
    "\n",
    "    \"\"\"\n",
    "    df = df\\\n",
    "        .withColumn('ArrivalTimeScheduled', f.unix_timestamp(f.col(\"ArrivalTimeScheduled\"), \"dd.MM.yyyy HH:mm\"))\\\n",
    "        .withColumn('DepartureTimeScheduled', f.unix_timestamp(f.col(\"DepartureTimeScheduled\"), \"dd.MM.yyyy HH:mm\"))\n",
    "    if(mode == 'forward') :\n",
    "        in_station = df.filter(df['SkipStation'] == 'false').filter(df['DepartureTimeScheduled'] > desired_time).filter(df['DepartureTimeScheduled'] < desired_time + allowed_timewindow).filter(df['station_name'] == stop_name).select('TripId','DepartureTimeScheduled')\n",
    "        next_station = df.filter(df['SkipStation'] == 'false').select('StopName','TripId','ArrivalTimeScheduled','TransportType').na.fill(\"Unknown\")\n",
    "        both = next_station.filter(next_station['StopName'] != stop_name).filter(next_station['ArrivalTimeScheduled'] < desired_time + 28800).join(in_station,on = 'TripId')\n",
    "        res = both.filter(both['ArrivalTimeScheduled'] > both['DepartureTimeScheduled'] ).select('TransportType','DepartureTimeScheduled','StopName','ArrivalTimeScheduled')\n",
    "        \n",
    "        tuples_train = res.rdd.map(lambda row:(row[0], row[1], row[2], row[3])).collect()\n",
    "        \n",
    "    else :\n",
    "        # We divide the allowed time window by two in the case that the arrival time is fixed, assuming that tolerence for waiting in arrival point is lower that at departure \n",
    "        in_station = df.filter(df['SkipStation'] == 'false').filter(df['ArrivalTimeScheduled'] < desired_time).filter(df['ArrivalTimeScheduled'] > desired_time - allowed_timewindow/2).filter(df['station_name'] == stop_name).select('TripId','ArrivalTimeScheduled')\n",
    "\n",
    "        next_station = df.filter(df['SkipStation'] == 'false').select('StopName','TripId','DepartureTimeScheduled','TransportType').na.fill(\"Unknown\")\n",
    "\n",
    "        both = next_station.filter(next_station['StopName'] != stop_name).filter(next_station['DepartureTimeScheduled'] > desired_time - 28800).join(in_station,on = 'TripId')\n",
    "        res = both.filter(both['ArrivalTimeScheduled'] > both['DepartureTimeScheduled'] ).select('TransportType','DepartureTimeScheduled','StopName','ArrivalTimeScheduled')\n",
    "        tuples_train = res.rdd.map(lambda row:(row[0], row[1], row[2], row[3])).collect()\n",
    "    tuples_with_walking = get_walking_stations(stop_name, desired_time, mode, isadvance)\n",
    "    all_tuples = tuples_train + tuples_with_walking\n",
    "    \n",
    "    \n",
    "    return all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_time(t):\n",
    "    \"\"\"Useful for seeing time for debugging\"\"\"\n",
    "    return datetime.fromtimestamp(abs(t)).strftime(\"%d.%m.%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's translate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+----------------+-----------+-------------+------------+\n",
      "|HALTESTELLEN_NAME|    ABFAHRTSZEIT|    ANKUNFTSZEIT|FAHRT_BEZEICHNER|LINIEN_TEXT|DURCHFAHRT_TF|station_name|\n",
      "+-----------------+----------------+----------------+----------------+-----------+-------------+------------+\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:59|               1|        IAD|        false|           A|\n",
      "|                D|17.10.2018 16:11|17.10.2018 16:10|               1|        IAD|        false|           D|\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:58|               2|        IAB|        false|           A|\n",
      "|                B|17.10.2018 16:01|17.10.2018 16:00|               2|        IAB|        false|           B|\n",
      "|                A|17.10.2018 15:00|17.10.2018 14:58|               3|        IAC|        false|           A|\n",
      "|                C|17.10.2018 15:26|17.10.2018 15:25|               3|        IAC|        false|           C|\n",
      "|                B|17.10.2018 16:11|17.10.2018 16:10|               4|       IBCI|        false|           B|\n",
      "|                C|17.10.2018 15:35|17.10.2018 15:30|               4|       IBCI|        false|           C|\n",
      "|                I|17.10.2018 15:20|            Null|               4|       IBCI|        false|           I|\n",
      "|                E|17.10.2018 15:00|17.10.2018 14:59|               5|        IAD|        false|           E|\n",
      "|                F|17.10.2018 15:49|17.10.2018 15:50|               5|        IEF|        false|           F|\n",
      "|                D|17.10.2018 16:13|17.10.2018 16:11|               6|        IEF|        false|           D|\n",
      "|                G|17.10.2018 16:45|17.10.2018 16:43|               6|       IDGH|        false|           G|\n",
      "|                H|17.10.2018 16:55|17.10.2018 16:50|               6|       IDGH|        false|           H|\n",
      "|                D|17.10.2018 20:00|17.10.2018 19:59|               7|       IDGH|        false|           D|\n",
      "|                A|17.10.2018 21:11|17.10.2018 21:10|               7|        IAD|        false|           A|\n",
      "|                B|17.10.2018 20:35|17.10.2018 19:58|               8|        IAD|        false|           B|\n",
      "|                A|17.10.2018 20:20|17.10.2018 21:00|               8|        IAB|        false|           A|\n",
      "|                C|17.10.2018 20:00|17.10.2018 19:58|               9|        IAB|        false|           C|\n",
      "|                A|17.10.2018 20:26|17.10.2018 20:25|               9|        IAC|        false|           A|\n",
      "|                I|17.10.2018 21:11|17.10.2018 21:10|              10|        IAC|        false|           I|\n",
      "|                C|17.10.2018 20:35|17.10.2018 20:30|              10|       IBCI|        false|           C|\n",
      "|                B|17.10.2018 20:20|            Null|              10|       IBCI|        false|           B|\n",
      "|                F|17.10.2018 20:00|17.10.2018 19:59|              11|       IBCI|        false|           F|\n",
      "|                E|17.10.2018 20:49|17.10.2018 20:50|              11|        IAD|        false|           E|\n",
      "|                H|17.10.2018 21:13|17.10.2018 21:11|              12|        IEF|        false|           H|\n",
      "|                G|17.10.2018 21:45|17.10.2018 21:43|              12|        IEF|        false|           G|\n",
      "|                D|17.10.2018 21:55|17.10.2018 21:50|              12|       IDGH|        false|           D|\n",
      "+-----------------+----------------+----------------+----------------+-----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "istdaten = swiss_data.join(stops_filter, swiss_data.HALTESTELLEN_NAME == stops_filter.station_name, 'inner')\n",
    "istdaten.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+--------------------+------+-------------+-----------+------------+\n",
      "|StopName|DepartureTimeScheduled|ArrivalTimeScheduled|TripId|TransportType|SkipStation|station_name|\n",
      "+--------+----------------------+--------------------+------+-------------+-----------+------------+\n",
      "|       A|      17.10.2018 15:00|    17.10.2018 14:59|     1|          IAD|      false|           A|\n",
      "|       D|      17.10.2018 16:11|    17.10.2018 16:10|     1|          IAD|      false|           D|\n",
      "|       A|      17.10.2018 15:00|    17.10.2018 14:58|     2|          IAB|      false|           A|\n",
      "|       B|      17.10.2018 16:01|    17.10.2018 16:00|     2|          IAB|      false|           B|\n",
      "|       A|      17.10.2018 15:00|    17.10.2018 14:58|     3|          IAC|      false|           A|\n",
      "|       C|      17.10.2018 15:26|    17.10.2018 15:25|     3|          IAC|      false|           C|\n",
      "|       B|      17.10.2018 16:11|    17.10.2018 16:10|     4|         IBCI|      false|           B|\n",
      "|       C|      17.10.2018 15:35|    17.10.2018 15:30|     4|         IBCI|      false|           C|\n",
      "|       I|      17.10.2018 15:20|                Null|     4|         IBCI|      false|           I|\n",
      "|       E|      17.10.2018 15:00|    17.10.2018 14:59|     5|          IAD|      false|           E|\n",
      "|       F|      17.10.2018 15:49|    17.10.2018 15:50|     5|          IEF|      false|           F|\n",
      "|       D|      17.10.2018 16:13|    17.10.2018 16:11|     6|          IEF|      false|           D|\n",
      "|       G|      17.10.2018 16:45|    17.10.2018 16:43|     6|         IDGH|      false|           G|\n",
      "|       H|      17.10.2018 16:55|    17.10.2018 16:50|     6|         IDGH|      false|           H|\n",
      "|       D|      17.10.2018 20:00|    17.10.2018 19:59|     7|         IDGH|      false|           D|\n",
      "|       A|      17.10.2018 21:11|    17.10.2018 21:10|     7|          IAD|      false|           A|\n",
      "|       B|      17.10.2018 20:35|    17.10.2018 19:58|     8|          IAD|      false|           B|\n",
      "|       A|      17.10.2018 20:20|    17.10.2018 21:00|     8|          IAB|      false|           A|\n",
      "|       C|      17.10.2018 20:00|    17.10.2018 19:58|     9|          IAB|      false|           C|\n",
      "|       A|      17.10.2018 20:26|    17.10.2018 20:25|     9|          IAC|      false|           A|\n",
      "|       I|      17.10.2018 21:11|    17.10.2018 21:10|    10|          IAC|      false|           I|\n",
      "|       C|      17.10.2018 20:35|    17.10.2018 20:30|    10|         IBCI|      false|           C|\n",
      "|       B|      17.10.2018 20:20|                Null|    10|         IBCI|      false|           B|\n",
      "|       F|      17.10.2018 20:00|    17.10.2018 19:59|    11|         IBCI|      false|           F|\n",
      "|       E|      17.10.2018 20:49|    17.10.2018 20:50|    11|          IAD|      false|           E|\n",
      "|       H|      17.10.2018 21:13|    17.10.2018 21:11|    12|          IEF|      false|           H|\n",
      "|       G|      17.10.2018 21:45|    17.10.2018 21:43|    12|          IEF|      false|           G|\n",
      "|       D|      17.10.2018 21:55|    17.10.2018 21:50|    12|         IDGH|      false|           D|\n",
      "+--------+----------------------+--------------------+------+-------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traduction = ' StopName string, DepartureTimeScheduled string, ArrivalTimeScheduled string, TripId string, TransportType string, SkipStation boolean'\n",
    "##, LineType string,\n",
    "traduction = list(map(lambda x: x.split()[0],traduction.split(',')))\n",
    "\n",
    "for german, english in zip(istdaten.columns, traduction):\n",
    "    istdaten = istdaten.withColumnRenamed(german, english)\n",
    "istdaten.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tuple(all_stations):\n",
    "    for row in all_stations:\n",
    "        print(row[0], nice_time(row[1]), row[2], nice_time(row[3]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired time at B :  1539785700.0 17.10.2018 16:15\n",
      "IBCI 17.10.2018 15:35 C 17.10.2018 16:10\n",
      "IBCI 17.10.2018 15:20 I 17.10.2018 16:10\n",
      "None 17.10.2018 16:08 D 17.10.2018 16:15\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "stop_name = \"B\"\n",
    "mode = \"backward\"\n",
    "desired_time = time.mktime(datetime.strptime(\"17.10.2018 16:15\", \"%d.%m.%Y %H:%M\").timetuple())\n",
    "window = 1800\n",
    "print(\"Desired time at B : \", desired_time, nice_time(desired_time))\n",
    "all_stations = get_all_possible_stations(istdaten, df_stops, stop_name, desired_time, mode, window)\n",
    "all_stations\n",
    "parse_tuple(all_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired time at A :  1539781140.0 17.10.2018 14:59\n",
      "IAD 17.10.2018 15:00 D 17.10.2018 16:10\n",
      "IAC 17.10.2018 15:00 C 17.10.2018 15:25\n",
      "IAB 17.10.2018 15:00 B 17.10.2018 16:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "stop_name = \"A\"\n",
    "mode = \"forward\"\n",
    "desired_time = time.mktime(datetime.strptime(\"17.10.2018 14:59\", \"%d.%m.%Y %H:%M\").timetuple())\n",
    "window = 1800\n",
    "print(\"Desired time at A : \", desired_time, nice_time(desired_time))\n",
    "all_stations = get_all_possible_stations(istdaten, df_stops, stop_name, desired_time, mode, window)\n",
    "all_stations\n",
    "parse_tuple(all_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deal with the fact that the time of arrival is not determinitic but a random variable. If we need to define it by a single value we decided to use the expectency, which is used to calculate the estimated time of arrival. The delay probability is used to find the probability for a train to arrive early enough that the user can safly catch the next train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_delay(station_name, line_id):\n",
    "    return 0 # average expected delay over dataset is 0, congrats SBB ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def get_delay_probability(station_name, line_id, delay):\n",
    "    row = delays_df.loc[(delays_df.LINIEN_TEXT == line_id) & (delays_df.HALTESTELLEN_NAME==station_name)]\n",
    "    if row.shape[0]>0:\n",
    "        return row[\"prob\"].values[0]\n",
    "    else:\n",
    "        return delays_df[\"prob\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/stations_dict_testing', 'rb') as handle:\n",
    "    stations_dict = pickle.load(handle)\n",
    "min_travel_times = np.load('./data/min_travel_times_testing.npy')\n",
    "\n",
    "def get_heuristic(city_a,city_b):\n",
    "    '''\n",
    "    Calculates the heuristic of time in minutes between two city taking a train\n",
    "    '''\n",
    "    # try to find connection in our adjacency matrix calculated in Heuristic.ipynb\n",
    "    if city_a in stations_dict and city_b in stations_dict:\n",
    "        i = stations_dict[city_a]\n",
    "        j = stations_dict[city_b]\n",
    "        estimated_time = min_travel_times[i,j]\n",
    "        if estimated_time!=1440:\n",
    "            # estimated_time=1440: no possible connection was found when building the Heuristic adjacency matrix\n",
    "            return float(estimated_time)\n",
    "    \n",
    "    avg_speed = 1600\n",
    "    try :\n",
    "        df_a = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_a).collect()\n",
    "        x_a = float(df_a[0]['KOORDE'])\n",
    "        y_a = float(df_a[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_a,'is invalide')\n",
    "        return 0\n",
    "    try :\n",
    "        df_b = df_stops.select('KOORDE','KOORDN').where(df_stops['station_name'] ==city_b).collect()\n",
    "        x_b = float(df_b[0]['KOORDE'])\n",
    "        y_b = float(df_b[0]['KOORDN'])\n",
    "    except IndexError :\n",
    "        print('Name ',city_b,'is invalide')\n",
    "        return 0\n",
    "    eucl_dist = math.sqrt((x_a-x_b)*(x_a-x_b)+ (y_a-y_b)*(y_a-y_b))\n",
    "    return eucl_dist/avg_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step :\n",
    "    def __init__(self,departure_station,arrival_station, depature_time,arrival_time, train):\n",
    "        self.departure_station = departure_station\n",
    "        self.arrival_station = arrival_station\n",
    "        self.depature_time = depature_time\n",
    "        self.arrival_time = arrival_time\n",
    "        self.train = train\n",
    "    def _get(self) :\n",
    "        #print('From : ',self.departure_station,',to : ', self.arrival_station, ',departing at : ', self.depature_time,\n",
    "        #     'with train', self.train, '\\n')\n",
    "        return {'departure' : self.departure_station, 'destination' : self.arrival_station, \\\n",
    "                'time of departure' : datetime.fromtimestamp(abs(self.depature_time)).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "                'time of arrival' : datetime.fromtimestamp(abs(self.arrival_time)).strftime('%Y-%m-%d %H:%M:%S'),\\\n",
    "                'type' : self.train}\n",
    "\n",
    "# Station keep each station and it's associated heuristic \n",
    "class Station :\n",
    "    def __init__(self,name, heuristic):\n",
    "        self.name = name\n",
    "        self.heuristic = heuristic\n",
    "    def _print(self) :\n",
    "        print('Station ',self.name,'with heursitic ', self.heuristic)\n",
    "\n",
    "# State describe a station visited at a certain time from a certain path, with a certain probability \n",
    "class State :\n",
    "    def __init__(self,station, eta, ps, previous_steps,last_train,pred_arrival_time):\n",
    "        # Name of the station at that state\n",
    "        self.station = station\n",
    "        \n",
    "        # Estimated time of arrival at that state. (in backward mode this is estimated time of departure)\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Probability to be at that state (given by probability to be at last state * probability to catch connection\n",
    "        #to previous state)\n",
    "        self.ps = ps\n",
    "        \n",
    "        # List of the step we took to get to that state\n",
    "        self.previous_steps = previous_steps\n",
    "        \n",
    "        # The linien_text of the last taken train\n",
    "        self.last_train = last_train\n",
    "        \n",
    "        # The predicted arrival time to that station (in backward mode this is predicted depature time of last transition)\n",
    "        self.pred_arrival_time = pred_arrival_time\n",
    "    def get_steps(self) :\n",
    "        steps_list = []\n",
    "        if (len(self.previous_steps) != 0):\n",
    "            for step in self.previous_steps :\n",
    "                steps_list.append(step._get())\n",
    "        else : print('Leave from home')\n",
    "        return steps_list\n",
    "    def __lt__ (self,other) :\n",
    "        return self.eta < other.eta\n",
    "    def __hash__ (self) :\n",
    "        return hash(self.eta)  \n",
    "    def _print(self) :\n",
    "        print('At',self.station.name,' the estimated time of arrival is ',self.eta\\\n",
    "              ,' with a probability of being here of ',self.ps, '\\n')\n",
    "        \n",
    "class End(Exception):\n",
    "    \"\"\"We found the right station\"\"\"\n",
    "    pass\n",
    "class Empty_queue(Exception):\n",
    "    \"\"\"Parameter where too restrictive, no path found and priority queue is empty\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementating the shortest path search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createstate(state,next_,destination,Pthresh,way):\n",
    "    \"\"\"Create a state resulting of a trip between station a and b :\n",
    "    Input : \n",
    "        - current state s at station a\n",
    "        - tuple containing the linien_text of the train t that goes from a to b, predicted\n",
    "        departure time at station a, predicted arrival time at station b and name of station b\n",
    "        - Final destination we are looking for and minimum probability we need. \n",
    "    Output :\n",
    "        - New State resulting from trip from a to b \"\"\"\n",
    "    linien_text = next_[0]\n",
    "    station_name = next_[2]\n",
    "    pred_departure = next_[1] \n",
    "    pred_arrival = next_[3]\n",
    "    # first we estimate the heuristic for this new station\n",
    "    heuristic = get_heuristic(station_name,destination)\n",
    "    station = Station(station_name,heuristic)\n",
    "    \n",
    "    \n",
    "    if(linien_text != None) :\n",
    "        # If we go to the next station by train\n",
    "        # get expected probability \n",
    "        Expected_delay = get_expected_delay(linien_text,station_name)\n",
    "        if (way == 'forward') :\n",
    "            # Calculate the new ETA\n",
    "            ETA = Expected_delay*60 + heuristic*60 + pred_arrival\n",
    "             # Calculates the probability that the last train arrives early enough to catch the next one (3min changing time)\n",
    "            delay = pred_departure- state.pred_arrival_time - 3*60\n",
    "            Pboard = get_delay_probability(state.station.name,linien_text,delay/60)\n",
    "            #Calculate the probability of the state which is the probability of the last state * probability of having made\n",
    "            # it to the next trip on time\n",
    "            Ps = state.ps * Pboard\n",
    "\n",
    "            # Update the step list \n",
    "            new_step = Step(state.station.name,station_name,pred_departure,pred_arrival,linien_text)\n",
    "        \n",
    "            Previous = state.previous_steps + [new_step]\n",
    "            return State(station,ETA,Ps,Previous,linien_text,pred_arrival)\n",
    "        else :\n",
    "            # Since the train departure time are assumed to be deterministic their is no delay of departure also eta is really estimated departure time\n",
    "            # in this way of calculation and must be negatuve as the priority list is selecting on smaller element\n",
    "            ETD = heuristic*60 - pred_departure\n",
    "             # Calculates the probability that the last train arrives early enough to catch the next one (3min changing time)\n",
    "            # NB here state.pred_arrival_time is actually the depature time of the next connection\n",
    "            delay = state.pred_arrival_time - pred_arrival\n",
    "            Pboard = get_delay_probability(state.station.name,linien_text,delay/60)\n",
    "            #Calculate the probability of the state which is the probability of the last state * probability of having made\n",
    "            # it to the next trip on time\n",
    "            Ps = state.ps * Pboard\n",
    "\n",
    "            # Update the step list \n",
    "            new_step = Step(station_name,state.station.name,pred_departure,pred_arrival,linien_text) \n",
    "            Previous = [new_step] + state.previous_steps \n",
    "            return State(station,ETD,Ps,Previous,linien_text,pred_departure)\n",
    "        \n",
    "        \n",
    "       \n",
    "    else : \n",
    "        # if we walked from the last station  \n",
    "        walking_time = pred_arrival - pred_departure \n",
    "        if (way == 'forward') :\n",
    "            ETA = state.eta - state.station.heuristic*60 + walking_time + heuristic*60\n",
    "            # if we walk we can leave when we want\n",
    "            Ps = state.ps\n",
    "            # Update the step list \n",
    "            new_step = Step(state.station.name,station_name,pred_departure,pred_arrival,'Walk')\n",
    "            Previous = state.previous_steps + [new_step]\n",
    "            return State(station,ETA,Ps,Previous,linien_text,pred_arrival)\n",
    "        else :\n",
    "            ETD = state.eta - state.station.heuristic*60 +  heuristic*60 + walking_time\n",
    "            # we assume that we must arrive 3 minute in advance or more to catch the train\n",
    "            Ps = state.ps\n",
    "            # Update the step list \n",
    "            new_step = Step(station_name,state.station.name,pred_departure,pred_arrival,'Walk')\n",
    "            Previous = [new_step] + state.previous_steps\n",
    "            return State(station,ETD,Ps,Previous,linien_text,pred_departure)\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firststep(From, To, t, Pthresh,way):\n",
    "    t = float(time.mktime(datetime.strptime(t, \"%d.%m.%Y %H:%M\").timetuple()))\n",
    "    start_heuristic = get_heuristic(From,To)\n",
    "    pqueue = PriorityQueue()\n",
    "    pqueue.put((float('inf'),\"empty_queue\"))\n",
    "    if (way == 'forward') :\n",
    "        current_station = Station(From,start_heuristic)\n",
    "        start_state = State(current_station,start_heuristic*60+t,1.0,[],\"starting\",t)\n",
    "        pqueue.put((start_state.eta,start_state))\n",
    "    else :\n",
    "        current_station = Station(To,start_heuristic)\n",
    "        start_state = State(current_station,start_heuristic*60-t,1.0,[],\"starting\",t)\n",
    "        pqueue.put((start_state.eta,start_state))\n",
    "    visited = visited_nodes()\n",
    "    visited.update(start_state,way)\n",
    "    return visited,pqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_step(priortity_list,Pthresh,destination,visited,way,reduced_df) :\n",
    "    \"\"\"For the first state in the priority_list find all possible next state and insert them into the priortity list \n",
    "    if their probability is highy<Ser than Pthresh\"\"\"\n",
    "    current_state = priortity_list.get()[1]\n",
    "    if (type(current_state) == str) :\n",
    "        raise Empty_queue(\"error\")\n",
    "    \n",
    "    #print(current_state.station.name,nice_time(current_state.eta),current_state.ps,current_state.last_train,len(current_state.previous_steps))\n",
    "    if (current_state.station.name == destination):\n",
    "        raise End(8,current_state)\n",
    "    # Get all stations to which we can go from current state\n",
    "    # Let's assume that getpossibletrip returns a list of tuple like \n",
    "    # (linien_text,next_station_name,predicted_arrival_time_current_station,predicted_departure_time, predicted_arrival_time) \n",
    "    # for each possible new trip. Predicted_departure_time is the predicted departure time at current state\n",
    "    # predicted_arrival_time the predicted arrival time in the reachable station\n",
    "    # If we are walking train_id is None, departure is the arrival time of last trip\n",
    "    # and arrival is departure time + estimation for walking time. \n",
    "    if (way == 'forward'):\n",
    "        \n",
    "        possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way)\n",
    "        \n",
    "    else :\n",
    "        if(current_state.last_train != \"starting\"):\n",
    "            # if we have a connections to catch and we are walking we should arrive 3 minutes in advance \n",
    "            possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way,isadvance = True)\n",
    "        else :\n",
    "            # if we are walking to destination we can arrive at desired time  \n",
    "            possible_next_stops = get_all_possible_stations(reduced_df,df_stops,current_state.station.name,current_state.pred_arrival_time,way)\n",
    "        \n",
    "    # For each next station, lets create the next state and add it to the Priority Queue\n",
    "    for next_ in possible_next_stops :\n",
    "        #print(next_[2],'leaving at ',nice_time(next_[1]), 'arriving at',nice_time(next_[3]),'using',next_[0])\n",
    "        if (current_state.last_train == None and next_[0] == None) :\n",
    "            # Here we want to avoid to do twice a trip by walking\n",
    "            continue\n",
    "        n_state = createstate(current_state,next_,destination,Pthresh,way)\n",
    "        if n_state.ps > Pthresh and visited.update(n_state,way) :\n",
    "            \n",
    "            priortity_list.put((n_state.eta,n_state))\n",
    "            \n",
    "    return priortity_list, visited\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visited nodes\n",
    "We want to model the set of visited nodes in a way that there are duplicates in the visited nodes only if the node has a higher probability of arriving there in a slower time. In all other cases only the fastest achieved node is saved in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_tuple_from_node(node):\n",
    "        return (node.station.name, node.eta, node.ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visited_nodes as a set of tuples, containing: (station, visit-time, certainity)\n",
    "class visited_nodes:\n",
    "    def __init__(self, initial_set=set([])):\n",
    "        self.nodes = initial_set\n",
    "    def update(self, new_node,way):\n",
    "        old_nodes = self.previous_visits(new_node)\n",
    "        new_node_tup = create_tuple_from_node(new_node)\n",
    "        \n",
    "        if len(old_nodes) == 0: #case when the node has not been explored yet.\n",
    "            self.add_to_visited(new_node_tup)\n",
    "            return True\n",
    "         \n",
    "        else: #case when the node has been explored and multiple optimal values are in the set\n",
    "            added = False\n",
    "            for n in old_nodes: #iterate through nodes and compare to new node\n",
    "                if (way == 'forward') :\n",
    "                    if self.compare_nodes_2_forward(n, new_node_tup): #node is added if better/equal than any node and replaces worse nodes\n",
    "                        added = True\n",
    "                else :\n",
    "                    if self.compare_nodes_2_backward(n, new_node_tup): #node is added if better/equal than any node and replaces worse nodes\n",
    "                        added = True\n",
    "            self.compare_in_set(new_node,way)\n",
    "            return added\n",
    "            \n",
    "    '''previous_visits takes a node and compares it to the already existing set of nodes that have been visited.\n",
    "        If a node has been visited before, the function hands out the previous visits in a list'''\n",
    "    def previous_visits(self, new_node):\n",
    "        return list(filter(lambda x: x[0] == new_node.station.name, self.nodes))\n",
    "    \n",
    "    '''add_to_visited takes a new node and adds it to the set of visited nodes'''\n",
    "    def add_to_visited(self, new_node_tup):\n",
    "        self.nodes.add(new_node_tup)\n",
    "        return None\n",
    "    \n",
    "    '''replace_old is used when a better node (higher probability and faster) appears. It takes a new node and adds\n",
    "        it to the set of visited nodes, while deleting the old one'''\n",
    "    def replace_old(self, new_node, old_node):\n",
    "        self.add_to_visited(new_node)\n",
    "        if old_node in self.nodes:\n",
    "            self.nodes.remove(old_node)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    '''takes two nodes and compares them according to the arrival time and probability. If a node is in some way\n",
    "        better than the existing it is stored. The function returns a boolean which indicates whether the value \n",
    "        has been stored (important to know for updating priority queue)'''\n",
    "    def compare_nodes_2_forward(self, node1, node2):\n",
    "    # Compare node by estimated time of arrival in which a lower eta is a fastest way\n",
    "        if node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is faster and has a higher proba\n",
    "            self.replace_old(node2, node1) #we replace the slow and improbable node\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] > node2[2]: #the node2 is only faser, but less certain\n",
    "            self.add_to_visited(node2) # add to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] < node2[2]: #the node2 is slower but more certain\n",
    "            self.add_to_visited(node2) #add it to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] == node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        elif node1[1] == node2[1] and node1[2] < node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False #the node2 is neither more certain nor faster, we drop it.\n",
    "    def compare_nodes_2_backward(self, node1, node2):\n",
    "        # Compare node by estimated time of departure in which a bigger etd is a fastest way\n",
    "        if node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is faster and has a higher proba\n",
    "            self.replace_old(node2, node1) #we replace the slow and improbable node\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] > node2[2]: #the node2 is only faser, but less certain\n",
    "            self.add_to_visited(node2) # add to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] > node2[1] and node1[2] < node2[2]: #the node2 is slower but more certain\n",
    "            self.add_to_visited(node2) #add it to optimal set\n",
    "            return True\n",
    "\n",
    "        elif node1[1] < node2[1] and node1[2] == node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        elif node1[1] == node2[1] and node1[2] < node2[2]:\n",
    "            self.replace_old(node2, node1)\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            return False #the node2 is neither more certain nor faster, we drop it.\n",
    "            \n",
    "    def compare_in_set(self, new_node,way):\n",
    "        old_nodes = self.previous_visits(new_node)\n",
    "        for n in old_nodes:\n",
    "            for m in old_nodes:\n",
    "                if (way == 'forward'):\n",
    "                    self.compare_nodes_2_forward(n, m)\n",
    "                else :\n",
    "                    self.compare_nodes_2_backward(n, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_toy(From,To,At,P,way):\n",
    "    steps = None\n",
    "    # initate the queue \n",
    "    visited,queue = firststep(From,To,At,P,way)\n",
    "    # load the Data for the day of the trip as well as one day before/after to account for midnight trip.\n",
    "    t = datetime.strptime(At, \"%d.%m.%Y %H:%M\").timetuple()    \n",
    "    # Running the query until the final station is found \n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            if (way =='forward'):\n",
    "                queue,visited = new_step(queue,P,To,visited,way,istdaten)\n",
    "            else :\n",
    "                queue,visited = new_step(queue,P,From,visited,way,istdaten)\n",
    "        except End as end: \n",
    "            # We found the soltution\n",
    "            final_state = end.args[1]\n",
    "            steps = pd.DataFrame(final_state.get_steps())\n",
    "            break\n",
    "        except Empty_queue:\n",
    "            print('No way was found with this probability threshold, try again with a lower threshold or stay home')\n",
    "            break\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few run to try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_time(t):\n",
    "    \"\"\"Useful for seeing time for debugging\"\"\"\n",
    "    return datetime.fromtimestamp(abs(t)).strftime(\"%d.%m.%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.12388428052266438mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure</th>\n",
       "      <th>destination</th>\n",
       "      <th>time of arrival</th>\n",
       "      <th>time of departure</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2018-10-17 15:25:00</td>\n",
       "      <td>2018-10-17 15:00:00</td>\n",
       "      <td>IAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2018-10-17 16:10:00</td>\n",
       "      <td>2018-10-17 15:35:00</td>\n",
       "      <td>IBCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  departure destination      time of arrival    time of departure  type\n",
       "0         A           C  2018-10-17 15:25:00  2018-10-17 15:00:00   IAC\n",
       "1         C           B  2018-10-17 16:10:00  2018-10-17 15:35:00  IBCI"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "steps = main_toy('A','B','17.10.2018 14:59',0.7,'forward')\n",
    "\n",
    "end = time.time()\n",
    "print('took {}mins'.format((end - start)/60))\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe that our algorithm did not picked shotest route AB neither longer one A-D-B, it picked the one with minimal time for a given probability**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
